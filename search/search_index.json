{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Foundations of Software Engineering Previous versions of the course website: F20 , F21 Overarching Questions When is a program good enough to ship? Have you built what the customer wanted? Why (and how) does Netflix deliberately and randomly take down its own servers? What can we learn from the Boeing 737 disaster? How did Twitter eradicate the Fail Whale? And what does it have to do with Ruby? How do you get a patch accepted into an open-source project? You can write code. Can you build software? Overview Successful software projects require more than just technical expertise. Figuring out what the client wants, collaborating in a team, managing complexity, mitigating risks, staying on time and budget, and determining under various constraints when a product is good enough to be shipped are at least equally important topics that often have a significant human component. 17-313 explores these issues while broadly covering the fundamentals of modern software engineering. Assuming reasonably solid programming skills (including unit testing and code-level design), we will explore the following topics: Process consideration for software development (How do avoid problems early? When and how much to design? When and how much to test? When and how to involve the customers? Agile methods...) Requirements elicitation, documentation, and evaluation (How to figure out what the customer really wants? Who else has an interest? How can we measure success objectively? How can we reliably document expectations? ...) Design for quality attributes (How can we design a system to be able to scale to millions of users? How can we design security into a system? ...) Strategies for quality assurance, including measurement, inspection, and static and dynamic analysis (What quality assurance strategy is best for a given system? What can we automate and when should we keep humans in the loop? How much testing and what kind of testing should we do? What qualities are important to assure beyond functional correctness? Can we evaluate usability, scalability, reliability, performance? How can we statically guarantee the absence of certain security issues? ...) Empirical methods in software engineering (How can we measure quality attributes such as performance, security, and reliability? How can we measure how users interact with the system? How can we know whether the difference matters? ...) Time and team management (How to estimate the duration and costs of a project? How to monitor progress and risks to recognize issues early? How to coordinate developers in a team? How to form and develop teams? How to select and motivate team members? How to deal with team dynamics such as social loafing? ...) Economics of software development (Business models, outsourcing, open source, ...) This course has a strong technical focus, and includes assignments with and without programming. Many assignments will also have written components. Students will get experience with team management and modern software-engineering tools. The course puts students on a fast track toward project management positions. Assignments (mostly done in groups) include: An introduction assignment where individual students will learn to engage with an existing code base. A requirements assignment in which each team will interview stakeholders to elicit and document requirements for a software system. An architecture assignment in which teams will train and deploy an ML model using microservices. A project in which each team contributes to an open source project of their choice. This involves identifying an issue in the existing project, understanding the development process of that project and how to contribute, and actually making a contribution such as fixing a bug or adding a feature. Extra credit will be awarded if the contribution is merged into the project. Class Calendar Weekly Schedule Date Lecture Recitation Reading Homework Deadline Mon Aug 29 Git Collaboration Slides Handout Quiz Homework 1 Due Thurs Sep 9 @ 11:59pm Handout Tue Aug 30 Intro Wed Aug 31 Thu Sep 01 Metrics and Measurement Fri Sep 02 Mon Sep 05 Angular.js and MVC Slides Handout Quiz Tue Sep 06 Case Study 737MAX News Article Wed Sep 07 Thu Sep 08 Code Archaeology Fri Sep 09 Homework 2A Due Thurs Sep 22 @ 11:59pm Handout Mon Sep 12 Tue Sep 13 Wed Sep 14 Thu Sep 15 Fri Sep 16 Mon Sep 19 Tue Sep 20 Wed Sep 21 Thu Sep 22 Fri Sep 23 Mon Sep 26 Tue Sep 27 Wed Sep 28 Thu Sep 29 Fri Sep 30 Mon Oct 03 Tue Oct 04 Wed Oct 05 Thu Oct 06 Fri Oct 07 Mon Oct 10 Tue Oct 11 Wed Oct 12 Thu Oct 13 Fri Oct 14 Mon Oct 17 Tue Oct 18 Wed Oct 19 Thu Oct 20 Fri Oct 21 Mon Oct 24 Tue Oct 25 Wed Oct 26 Thu Oct 27 Fri Oct 28 Mon Oct 31 Tue Nov 01 Wed Nov 02 Thu Nov 03 Fri Nov 04 Mon Nov 07 Tue Nov 08 Wed Nov 09 Thu Nov 10 Fri Nov 11 Mon Nov 14 Tue Nov 15 Wed Nov 16 Thu Nov 17 Fri Nov 18 Mon Nov 21 Tue Nov 22 Wed Nov 23 Thu Nov 24 Fri Nov 25 Mon Nov 28 Tue Nov 29 Wed Nov 30 Thu Dec 01 Fri Dec 02 Mon Dec 05 Tue Dec 06 Wed Dec 07 Thu Dec 08 Fri Dec 09 Staff Instructors Christopher Timperley ctimperley@cmu.edu Daye Nam dayen@andrew.cmu.edu Michael Hilton mhilton@cmu.edu Rohan Padhye rohanpadhye@cmu.edu Teaching Assistants Angela Zhang angelaz1@andrew.cmu.edu Anuda Weerasinghe wweerasi@andrew.cmu.edu Maggie Huang maggieh2@andrew.cmu.edu Mahima Pannala mpannala@andrew.cmu.edu Wode \"Nimo\" Ni woden@cs.cmu.edu Tak-Ho Lee takhol@andrew.cmu.edu Victor Huang hweiqivi@andrew.cmu.edu Victor Andres Alfonzo vaa@andrew.cmu.edu","title":"Home"},{"location":"#foundations-of-software-engineering","text":"Previous versions of the course website: F20 , F21","title":"Foundations of Software Engineering"},{"location":"#overarching-questions","text":"When is a program good enough to ship? Have you built what the customer wanted? Why (and how) does Netflix deliberately and randomly take down its own servers? What can we learn from the Boeing 737 disaster? How did Twitter eradicate the Fail Whale? And what does it have to do with Ruby? How do you get a patch accepted into an open-source project? You can write code. Can you build software?","title":"Overarching Questions"},{"location":"#overview","text":"Successful software projects require more than just technical expertise. Figuring out what the client wants, collaborating in a team, managing complexity, mitigating risks, staying on time and budget, and determining under various constraints when a product is good enough to be shipped are at least equally important topics that often have a significant human component. 17-313 explores these issues while broadly covering the fundamentals of modern software engineering. Assuming reasonably solid programming skills (including unit testing and code-level design), we will explore the following topics: Process consideration for software development (How do avoid problems early? When and how much to design? When and how much to test? When and how to involve the customers? Agile methods...) Requirements elicitation, documentation, and evaluation (How to figure out what the customer really wants? Who else has an interest? How can we measure success objectively? How can we reliably document expectations? ...) Design for quality attributes (How can we design a system to be able to scale to millions of users? How can we design security into a system? ...) Strategies for quality assurance, including measurement, inspection, and static and dynamic analysis (What quality assurance strategy is best for a given system? What can we automate and when should we keep humans in the loop? How much testing and what kind of testing should we do? What qualities are important to assure beyond functional correctness? Can we evaluate usability, scalability, reliability, performance? How can we statically guarantee the absence of certain security issues? ...) Empirical methods in software engineering (How can we measure quality attributes such as performance, security, and reliability? How can we measure how users interact with the system? How can we know whether the difference matters? ...) Time and team management (How to estimate the duration and costs of a project? How to monitor progress and risks to recognize issues early? How to coordinate developers in a team? How to form and develop teams? How to select and motivate team members? How to deal with team dynamics such as social loafing? ...) Economics of software development (Business models, outsourcing, open source, ...) This course has a strong technical focus, and includes assignments with and without programming. Many assignments will also have written components. Students will get experience with team management and modern software-engineering tools. The course puts students on a fast track toward project management positions. Assignments (mostly done in groups) include: An introduction assignment where individual students will learn to engage with an existing code base. A requirements assignment in which each team will interview stakeholders to elicit and document requirements for a software system. An architecture assignment in which teams will train and deploy an ML model using microservices. A project in which each team contributes to an open source project of their choice. This involves identifying an issue in the existing project, understanding the development process of that project and how to contribute, and actually making a contribution such as fixing a bug or adding a feature. Extra credit will be awarded if the contribution is merged into the project.","title":"Overview"},{"location":"#class-calendar","text":"","title":"Class Calendar"},{"location":"#weekly-schedule","text":"Date Lecture Recitation Reading Homework Deadline Mon Aug 29 Git Collaboration Slides Handout Quiz Homework 1 Due Thurs Sep 9 @ 11:59pm Handout Tue Aug 30 Intro Wed Aug 31 Thu Sep 01 Metrics and Measurement Fri Sep 02 Mon Sep 05 Angular.js and MVC Slides Handout Quiz Tue Sep 06 Case Study 737MAX News Article Wed Sep 07 Thu Sep 08 Code Archaeology Fri Sep 09 Homework 2A Due Thurs Sep 22 @ 11:59pm Handout Mon Sep 12 Tue Sep 13 Wed Sep 14 Thu Sep 15 Fri Sep 16 Mon Sep 19 Tue Sep 20 Wed Sep 21 Thu Sep 22 Fri Sep 23 Mon Sep 26 Tue Sep 27 Wed Sep 28 Thu Sep 29 Fri Sep 30 Mon Oct 03 Tue Oct 04 Wed Oct 05 Thu Oct 06 Fri Oct 07 Mon Oct 10 Tue Oct 11 Wed Oct 12 Thu Oct 13 Fri Oct 14 Mon Oct 17 Tue Oct 18 Wed Oct 19 Thu Oct 20 Fri Oct 21 Mon Oct 24 Tue Oct 25 Wed Oct 26 Thu Oct 27 Fri Oct 28 Mon Oct 31 Tue Nov 01 Wed Nov 02 Thu Nov 03 Fri Nov 04 Mon Nov 07 Tue Nov 08 Wed Nov 09 Thu Nov 10 Fri Nov 11 Mon Nov 14 Tue Nov 15 Wed Nov 16 Thu Nov 17 Fri Nov 18 Mon Nov 21 Tue Nov 22 Wed Nov 23 Thu Nov 24 Fri Nov 25 Mon Nov 28 Tue Nov 29 Wed Nov 30 Thu Dec 01 Fri Dec 02 Mon Dec 05 Tue Dec 06 Wed Dec 07 Thu Dec 08 Fri Dec 09","title":"Weekly Schedule"},{"location":"#staff","text":"","title":"Staff"},{"location":"#instructors","text":"","title":"Instructors"},{"location":"#teaching-assistants","text":"","title":"Teaching Assistants"},{"location":"syllabus/","text":"Course Syllabus and Policies The course is currently planned to be entirely in person for lectures, and recitation. Most office hours will be in person, but some might be held over zoom as well. The course uses Canvas (and Gradescope) for homework submission, grading, discussion, questions, announcements, lecture recordings, and supplementary documents; slides will be posted here; GitHub is used to coordinate group work. We will also use Slack for communication and group work. See Canvas for the sign up link. Waitlist The class has a wait list long enough that we don't expect to clear it all. However, we will add as many students as we can. We also will be offering 17-313 in the Spring for those who are unable to get in this fall. Prerequisites No formal prerequisites, but you will get more out of the course if you have experience with some larger development projects, for example, through larger class projects (e.g., 17-214, 15-410), internships, or open-source contributions. If you have questions, please don't hesitate to reach out to the class instructors. Communication We make announcements through Canvas, including clarifying homework assignments. We will also be using Slack both for communication with the instructors, and to support your group work communication. The instructors and TAs hold weekly office hours and are reachable by email and Slack. Reach out for additional appointments. Teamwork Teamwork is an essential part of this course. Most assignments are done in teams of 3-5 students. Teams will be assigned by the instructor and stay together for multiple assignments. Guidance on teamwork, reflection, and conflict resolution will be provided throughout the semester and are an essential component of the class. Most assignments have a component that is graded for the entire group and a component that is graded individually. The team policy posted on Canvas applies and describes roles and teams and how to deal with conflicts and imbalances. Textbook Various readings throughout the semester available online or through the library; we do not have a single text book but rather assemble readings from different sources. As optional supplementary reading consider the (Freely available) Software Engineering at Google, Lessons Learned from Programming Over Time . Assessment Evaluation will be based on the following distribution: 60% assignments, 20% midterm, 20% participation (including in-class exercises, pre-class reading quizzes, and recitation exercises). Time management This is a 12-unit course, and it is our intention to manage it so that you spend close to 12 hours a week on the course, on average. In general, 4 hours/week will be spent in class and 8 hours on reading and assignments. Notice that most homework is done in groups, so please account for the overhead and decreased time flexibility that comes with groupwork. Please feel free to give the course staff feedback on how much time the course is taking for you. Late work policy Late work will receive feedback but no credit. Due to heavy reliance on teamwork in this course there are no late days. Exceptions to this policy will be made only in extraordinary circumstances, almost always involving a family or medical emergency---with your academic advisor or the Dean of Student Affairs requesting the exception on your behalf. Accommodations for travel (e.g., for interviews) are possible if requested at least 3 days in advance. Please communicate also with your team about timing issues. Writing Describing tradeoffs among decisions and communication with less technical stakeholders are key aspects of this class. Most homework assignments have a component that require discussing issues in written form or reflecting about experiences. To practice writing skills, the Global Communications Center (GCC) offers one-on-one help for students, along with workshops. The instructors are also happy to provide additional guidance if requested. Professionalism Your classmates are your colleagues. This is particularly true in this course, where we aim to provide you with principles, practices, tools, and paradigms that will enable you to be an effective, real-world Software Engineer. We ask that you treat one another like the professionals you are and that you are preparing to be. To that end, we will not tolerate harassement in this class. We define harassment as unwelcome or hostile behavior of an ad hominem nature, i.e., that focuses not on ideas but on people and identity. This includes offensive verbal or written comments in reference to gender, sexual orientation, disability, physical appearance, race, or religion; sexual images in public spaces; deliberate intimidation, stalking, following, harassing photography or recording, sustained disruption of class meetings, inappropriate physical contact, and unwelcome sexual attention. Harassment is against the law and we have no tolerance for it, and neither does the university. Even when behavior does not rise to the level of harassment (even if you think you're \"just joking!\"), it can still make people very uncomfortable, and harm their educational and professional career by forcing them to devote mental energy to something other than the material they are trying to learn or the professional successes they are trying to acheive. However, we expect that we do not need to threaten you to earn your respect on this matter: we simply ask that you treat one another like professionals, in the most positive sense. This has two implications: - If you feel someone is violating these principles (for example, with a joke that could be interpreted as sexist, racist, or exclusionary), and you feel you have the standing to do so, speak up! Do not be a bystander to unprofessional behavior. - If you do not feel comfortable doing so, and/or if the behavior persists, send a private email to the course instructors or set up a meeting with us to discuss the matter. We will preserve your anonymity. We, the course staff, are committed to affording you the same respect we ask you to afford one another. If you feel that we are not doing so, we hope you will feel comfortable either telling us so directly, or approaching another one of the course staff with your concerns. (Thank you to Shriram Krishnamurthi and Evan Peck for sharing their own policies, from which we drew inspiration for this one.) Academic honesty and collaboration The usual policies apply, especially the University Policy on Academic Integrity. Many of the assignments will be done in groups. We expect that group members collaborate with one another, but that groups work independently from one another, not exchanging results with other groups. Within groups, we expect that you are honest about your contribution to the group's work. This implies not taking credit for others' work and not covering for team members that have not contributed to the team. Otherwise, our expectations regarding academic honestly and collaboration for group work are the same as for individual work, substituting elevated to the level of \"group.\" The course includes both individual assignments and individual components of group assignments. Although your solutions for individual parts will be based on the content produced for the group component (e.g., written reflections on lessons learned), we treat individual component of group assignments as equivalent to individual assignments overall, and expect you to complete such components independently of your groupmates. The rest of this academic honesty and collaboration content is taken from the policy used in 17-214, which we reuse almost directly (with minor modifications, and attribution). \"You may not copy any part of a solution to a problem that was written by another student, or was developed together with another student, or was copied from another unauthorized source such as the Internet. You may not look at another student's solution, even if you have completed your own, nor may you knowingly give your solution to another student or leave your solution where another student can see it. Here are some examples of behavior that are inappropriate: Copying or retyping, or referring to, files or parts of files (such as source code, written text, or unit tests) from another person or source (whether in final or draft form, regardless of the permissions set on the associated files) while producing your own. This is true even if your version includes minor modifications such as style or variable name changes or minor logic modifications. Getting help that you do not fully understand, and from someone whom you do not acknowledge on your solution. Writing, using, or submitting a program that attempts to alter or erase grading information or otherwise compromise security of course resources. Lying to course staff. Giving copies of work to others, or allowing someone else to copy or refer to your code or written assignment to produce their own, either in draft or final form. This includes making your work publicly available in a way that other students (current or future) can access your solutions, even if others' access is accidental or incidental to your goals. Beware the privacy settings on your open source accounts! Coaching others step-by-step without them understanding your help. If any of your work contains any statement that was not written by you, you must put it in quotes and cite the source. If you are paraphrasing an idea you read elsewhere, you must acknowledge the source. Using existing material without proper citation is plagiarism, a form of cheating. If there is any question about whether the material is permitted, you must get permission in advance. We will be using automated systems to detect software plagiarism. It is not considered cheating to clarify vague points in the assignments, lectures, lecture notes; to give help or receive help in using the computer systems, compilers, debuggers, profilers, or other facilities; or to discuss ideas at a very high level, without referring to or producing code. Any violation of this policy is cheating. The minimum penalty for cheating (including plagiarism) will be a zero grade for the whole assignment. Cheating incidents will also be reported through University channels, with possible additional disciplinary action (see the above-linked University Policy on Academic Integrity). If you have any question about how this policy applies in a particular situation, ask the instructors or TAs for clarification.\" Note that the instructors respect honesty in these (and indeed most!) situations. Accommodations If you wish to request an accommodation due to a documented disability, please inform the instructor as soon as possible and contact Disability Resources at 412.268.2013 or access@andrew.cmu.edu. Policy on healthcare-related absence We don't record our lectures, because they are highly interactive and tricky to record, but we post slides at the end of the day. Please go over them and come to any of the instructors\u2019 office hours to discuss the material for the participation credit. A Note on Self Care A note on self care. Please take care of yourself. Do your best to maintain a healthy lifestyle this semester by eating well, exercising, avoiding drugs and alcohol, getting enough sleep and taking some time to relax. This will help you achieve your goals and cope with stress. All of us benefit from support during times of struggle. You are not alone. There are many helpful resources available on campus and an important part of the college experience is learning how to ask for help. Asking for support sooner rather than later is often helpful. If you or anyone you know experiences any academic stress, difficult life events, or feelings like anxiety or depression, we strongly encourage you to seek support. Counseling and Psychological Services (CaPS) is here to help: call 412-268-2922 and visit their website at http://www.cmu.edu/counseling/. Consider reaching out to a friend, faculty or family member you trust for help getting connected to the support that can help.","title":"Syllabus"},{"location":"syllabus/#course-syllabus-and-policies","text":"The course is currently planned to be entirely in person for lectures, and recitation. Most office hours will be in person, but some might be held over zoom as well. The course uses Canvas (and Gradescope) for homework submission, grading, discussion, questions, announcements, lecture recordings, and supplementary documents; slides will be posted here; GitHub is used to coordinate group work. We will also use Slack for communication and group work. See Canvas for the sign up link.","title":"Course Syllabus and Policies"},{"location":"syllabus/#waitlist","text":"The class has a wait list long enough that we don't expect to clear it all. However, we will add as many students as we can. We also will be offering 17-313 in the Spring for those who are unable to get in this fall.","title":"Waitlist"},{"location":"syllabus/#prerequisites","text":"No formal prerequisites, but you will get more out of the course if you have experience with some larger development projects, for example, through larger class projects (e.g., 17-214, 15-410), internships, or open-source contributions. If you have questions, please don't hesitate to reach out to the class instructors.","title":"Prerequisites"},{"location":"syllabus/#communication","text":"We make announcements through Canvas, including clarifying homework assignments. We will also be using Slack both for communication with the instructors, and to support your group work communication. The instructors and TAs hold weekly office hours and are reachable by email and Slack. Reach out for additional appointments.","title":"Communication"},{"location":"syllabus/#teamwork","text":"Teamwork is an essential part of this course. Most assignments are done in teams of 3-5 students. Teams will be assigned by the instructor and stay together for multiple assignments. Guidance on teamwork, reflection, and conflict resolution will be provided throughout the semester and are an essential component of the class. Most assignments have a component that is graded for the entire group and a component that is graded individually. The team policy posted on Canvas applies and describes roles and teams and how to deal with conflicts and imbalances.","title":"Teamwork"},{"location":"syllabus/#textbook","text":"Various readings throughout the semester available online or through the library; we do not have a single text book but rather assemble readings from different sources. As optional supplementary reading consider the (Freely available) Software Engineering at Google, Lessons Learned from Programming Over Time .","title":"Textbook"},{"location":"syllabus/#assessment","text":"Evaluation will be based on the following distribution: 60% assignments, 20% midterm, 20% participation (including in-class exercises, pre-class reading quizzes, and recitation exercises).","title":"Assessment"},{"location":"syllabus/#time-management","text":"This is a 12-unit course, and it is our intention to manage it so that you spend close to 12 hours a week on the course, on average. In general, 4 hours/week will be spent in class and 8 hours on reading and assignments. Notice that most homework is done in groups, so please account for the overhead and decreased time flexibility that comes with groupwork. Please feel free to give the course staff feedback on how much time the course is taking for you.","title":"Time management"},{"location":"syllabus/#late-work-policy","text":"Late work will receive feedback but no credit. Due to heavy reliance on teamwork in this course there are no late days. Exceptions to this policy will be made only in extraordinary circumstances, almost always involving a family or medical emergency---with your academic advisor or the Dean of Student Affairs requesting the exception on your behalf. Accommodations for travel (e.g., for interviews) are possible if requested at least 3 days in advance. Please communicate also with your team about timing issues.","title":"Late work policy"},{"location":"syllabus/#writing","text":"Describing tradeoffs among decisions and communication with less technical stakeholders are key aspects of this class. Most homework assignments have a component that require discussing issues in written form or reflecting about experiences. To practice writing skills, the Global Communications Center (GCC) offers one-on-one help for students, along with workshops. The instructors are also happy to provide additional guidance if requested.","title":"Writing"},{"location":"syllabus/#professionalism","text":"Your classmates are your colleagues. This is particularly true in this course, where we aim to provide you with principles, practices, tools, and paradigms that will enable you to be an effective, real-world Software Engineer. We ask that you treat one another like the professionals you are and that you are preparing to be. To that end, we will not tolerate harassement in this class. We define harassment as unwelcome or hostile behavior of an ad hominem nature, i.e., that focuses not on ideas but on people and identity. This includes offensive verbal or written comments in reference to gender, sexual orientation, disability, physical appearance, race, or religion; sexual images in public spaces; deliberate intimidation, stalking, following, harassing photography or recording, sustained disruption of class meetings, inappropriate physical contact, and unwelcome sexual attention. Harassment is against the law and we have no tolerance for it, and neither does the university. Even when behavior does not rise to the level of harassment (even if you think you're \"just joking!\"), it can still make people very uncomfortable, and harm their educational and professional career by forcing them to devote mental energy to something other than the material they are trying to learn or the professional successes they are trying to acheive. However, we expect that we do not need to threaten you to earn your respect on this matter: we simply ask that you treat one another like professionals, in the most positive sense. This has two implications: - If you feel someone is violating these principles (for example, with a joke that could be interpreted as sexist, racist, or exclusionary), and you feel you have the standing to do so, speak up! Do not be a bystander to unprofessional behavior. - If you do not feel comfortable doing so, and/or if the behavior persists, send a private email to the course instructors or set up a meeting with us to discuss the matter. We will preserve your anonymity. We, the course staff, are committed to affording you the same respect we ask you to afford one another. If you feel that we are not doing so, we hope you will feel comfortable either telling us so directly, or approaching another one of the course staff with your concerns. (Thank you to Shriram Krishnamurthi and Evan Peck for sharing their own policies, from which we drew inspiration for this one.)","title":"Professionalism"},{"location":"syllabus/#academic-honesty-and-collaboration","text":"The usual policies apply, especially the University Policy on Academic Integrity. Many of the assignments will be done in groups. We expect that group members collaborate with one another, but that groups work independently from one another, not exchanging results with other groups. Within groups, we expect that you are honest about your contribution to the group's work. This implies not taking credit for others' work and not covering for team members that have not contributed to the team. Otherwise, our expectations regarding academic honestly and collaboration for group work are the same as for individual work, substituting elevated to the level of \"group.\" The course includes both individual assignments and individual components of group assignments. Although your solutions for individual parts will be based on the content produced for the group component (e.g., written reflections on lessons learned), we treat individual component of group assignments as equivalent to individual assignments overall, and expect you to complete such components independently of your groupmates. The rest of this academic honesty and collaboration content is taken from the policy used in 17-214, which we reuse almost directly (with minor modifications, and attribution). \"You may not copy any part of a solution to a problem that was written by another student, or was developed together with another student, or was copied from another unauthorized source such as the Internet. You may not look at another student's solution, even if you have completed your own, nor may you knowingly give your solution to another student or leave your solution where another student can see it. Here are some examples of behavior that are inappropriate: Copying or retyping, or referring to, files or parts of files (such as source code, written text, or unit tests) from another person or source (whether in final or draft form, regardless of the permissions set on the associated files) while producing your own. This is true even if your version includes minor modifications such as style or variable name changes or minor logic modifications. Getting help that you do not fully understand, and from someone whom you do not acknowledge on your solution. Writing, using, or submitting a program that attempts to alter or erase grading information or otherwise compromise security of course resources. Lying to course staff. Giving copies of work to others, or allowing someone else to copy or refer to your code or written assignment to produce their own, either in draft or final form. This includes making your work publicly available in a way that other students (current or future) can access your solutions, even if others' access is accidental or incidental to your goals. Beware the privacy settings on your open source accounts! Coaching others step-by-step without them understanding your help. If any of your work contains any statement that was not written by you, you must put it in quotes and cite the source. If you are paraphrasing an idea you read elsewhere, you must acknowledge the source. Using existing material without proper citation is plagiarism, a form of cheating. If there is any question about whether the material is permitted, you must get permission in advance. We will be using automated systems to detect software plagiarism. It is not considered cheating to clarify vague points in the assignments, lectures, lecture notes; to give help or receive help in using the computer systems, compilers, debuggers, profilers, or other facilities; or to discuss ideas at a very high level, without referring to or producing code. Any violation of this policy is cheating. The minimum penalty for cheating (including plagiarism) will be a zero grade for the whole assignment. Cheating incidents will also be reported through University channels, with possible additional disciplinary action (see the above-linked University Policy on Academic Integrity). If you have any question about how this policy applies in a particular situation, ask the instructors or TAs for clarification.\" Note that the instructors respect honesty in these (and indeed most!) situations.","title":"Academic honesty and collaboration"},{"location":"syllabus/#accommodations","text":"If you wish to request an accommodation due to a documented disability, please inform the instructor as soon as possible and contact Disability Resources at 412.268.2013 or access@andrew.cmu.edu.","title":"Accommodations"},{"location":"syllabus/#policy-on-healthcare-related-absence","text":"We don't record our lectures, because they are highly interactive and tricky to record, but we post slides at the end of the day. Please go over them and come to any of the instructors\u2019 office hours to discuss the material for the participation credit.","title":"Policy on healthcare-related absence"},{"location":"syllabus/#a-note-on-self-care","text":"A note on self care. Please take care of yourself. Do your best to maintain a healthy lifestyle this semester by eating well, exercising, avoiding drugs and alcohol, getting enough sleep and taking some time to relax. This will help you achieve your goals and cope with stress. All of us benefit from support during times of struggle. You are not alone. There are many helpful resources available on campus and an important part of the college experience is learning how to ask for help. Asking for support sooner rather than later is often helpful. If you or anyone you know experiences any academic stress, difficult life events, or feelings like anxiety or depression, we strongly encourage you to seek support. Counseling and Psychological Services (CaPS) is here to help: call 412-268-2922 and visit their website at http://www.cmu.edu/counseling/. Consider reaching out to a friend, faculty or family member you trust for help getting connected to the support that can help.","title":"A Note on Self Care"},{"location":"assignments/HW1/","text":"Homework 1: Hello, Teedy! Learning Goals Familiarize yourself with an existing software project Download, install and run an existing software project Run an evaluation tool and collect metrics Evaluate the results of these metrics Background Git and GitHub: Git Documentation Git Flow GitHub Basics GitHub's Flow GitHub Cross-Referencing Specification Welcome to the team! To start your journey on this project, your first task is to become familiar with an existing piece of software. Eventually you will be adding new features, but the first step is to simply download, run, evaluate, and explore the current software product. The project we will be building on this semester is an open source document management system, Teedy . We will be using a class-specific fork of Teedy, whose repository is located at: https://github.com/CMU-313/Teedy This fork is based off https://github.com/sismics/docs and contains minor tweaks to make the project easier to modify and debug. Forking from the class repository will allow you to send pull requests to the instructors, which is the primary way of submitting code deliverables for this homework. Getting Started: Your first step should be to fork the repository and then follow the installation instructions in README.md. You must build and run Teedy natively on your machine (via the manual installation instructions) rather than following the Docker instructions. After building Teedy and its dependencies, you should follow the rest of the Getting Started instructions to run a Teedy instance on your machine. Once you have run Teedy successfully, you should be able to navigate to http://localhost:8080/src (if this doesn't work, try navigating to http://localhost:8080 ) and see a web page with a login screen. By default, Teedy will be deployed to port 8080 on your machine. You may change this port number (e.g., to avoid conflict with another process running on your machine). If the process of installing and running Teedy takes you more than a few hours, STOP and ask for help on Slack. Collecting Metrics: Once you have Teedy up and running locally, proceed to evaluate it using Google Lighthouse . You can run Lighthouse as a stand alone application, or using the audit tab of Google Developer Tools. After you run Lighthouse, it will give you a score for various dimensions: Performance, Accessibility, Best Practices, and SEO. Additionally, you can measure test coverage. This will be done every time you run the tests via maven mvn test , using the Jacoco tool. After looking over the metrics, pick one metric to improve (Performance, Accessibility, Best Practices, SEO, or Code Coverage). The Lighthouse reports will give you some suggestions as to how to improve a score. The only requirements are that your change should affect the metric's score, and that the change should involve a commit to the repo. HINT: Because of this, you might want to avoid trying to change the performance score. First, open an issue in the https://github.com/CMU-313/Teedy/issues to declare what aspect of Teedy you will be improving. You should look through existing issues, if any, to avoid duplicates. In the issue description, mention the current score you observed and the warning that you are targeting. ~~Tag the issue with one or more of the existing labels as appropriate, add it to milestone \"HW1\", and~~ assign yourself (do this by commenting \"I would like to work on this please!\"). In your own fork, create a feature branch, implement the change, test it out locally, and commit your changes. Your commit message(s) must clearly describe what's changing. Once you are satisfied, open a pull request in the parent repository. The PR should link the issue that you previously opened (e.g. using the \"resolve(s)\" keyword), summarize the changes, and describe how much the score improved by due to your change. After you have completed this task, we will ask you to reflect on the nature of metrics. To do this, you will answer the following questions about metrics, specifically in the context of Teedy. You should focus your answers for each of these questions on the metric that you chose to improve. What properties do we care about, and how do we measure them? What is being measured? Does it (to what degree) capture the thing you care about? What are its limitations? How should this metric be incorporated into process? Check in gate? Once a month? Etc. What are potentially negative side effects or incentives? Deliverables and Deadlines There are three (3) deliverables and one (1) deadline for this homework. Individual Component -- 100 points -- due Thursday, September 9th, 23:59 Create an issue in the parent repository, which must: Mention the metric you are targeting. Mention the current metric scores. Be assigned to yourself. ~~Be tagged with at least one appropriate label. Be associated with the HW1 milestone.~~ Create a pull request in the parent repository, which must: Reference the issue created above. Describe the fix and improvement to the score. Answer the following questions on Gradescope about the metric you chose: - What properties do we care about, and how do we measure it? - What is being measured? Does it (to what degree) capture the thing you care about? What are its limitations? - How should it be incorporated into process? Check in gate? Once a month? Etc. - What are potentially negative side effects or incentives? Grading This homework is worth 100 points. Running the project, making the change, and committing it properly constitutes 50 points (50%), and the reflection questions constitutes 50 points (50%). To receive full credit for the group component, we expect: The correct use of tools and technology, including Git, GitHub, and Lighthouse. Answers to the questions that demonstrate understanding of the benefits and limitations of software metrics, specifically in the context of Teedy. This analysis should go beyond superficial statements, mere descriptions, and truisms, which ties specifically to the context of this assignment.","title":"Homework 1"},{"location":"assignments/HW1/#homework-1-hello-teedy","text":"","title":"Homework 1: Hello, Teedy!"},{"location":"assignments/HW1/#learning-goals","text":"Familiarize yourself with an existing software project Download, install and run an existing software project Run an evaluation tool and collect metrics Evaluate the results of these metrics","title":"Learning Goals"},{"location":"assignments/HW1/#background","text":"Git and GitHub: Git Documentation Git Flow GitHub Basics GitHub's Flow GitHub Cross-Referencing","title":"Background"},{"location":"assignments/HW1/#specification","text":"Welcome to the team! To start your journey on this project, your first task is to become familiar with an existing piece of software. Eventually you will be adding new features, but the first step is to simply download, run, evaluate, and explore the current software product. The project we will be building on this semester is an open source document management system, Teedy . We will be using a class-specific fork of Teedy, whose repository is located at: https://github.com/CMU-313/Teedy This fork is based off https://github.com/sismics/docs and contains minor tweaks to make the project easier to modify and debug. Forking from the class repository will allow you to send pull requests to the instructors, which is the primary way of submitting code deliverables for this homework. Getting Started: Your first step should be to fork the repository and then follow the installation instructions in README.md. You must build and run Teedy natively on your machine (via the manual installation instructions) rather than following the Docker instructions. After building Teedy and its dependencies, you should follow the rest of the Getting Started instructions to run a Teedy instance on your machine. Once you have run Teedy successfully, you should be able to navigate to http://localhost:8080/src (if this doesn't work, try navigating to http://localhost:8080 ) and see a web page with a login screen. By default, Teedy will be deployed to port 8080 on your machine. You may change this port number (e.g., to avoid conflict with another process running on your machine). If the process of installing and running Teedy takes you more than a few hours, STOP and ask for help on Slack. Collecting Metrics: Once you have Teedy up and running locally, proceed to evaluate it using Google Lighthouse . You can run Lighthouse as a stand alone application, or using the audit tab of Google Developer Tools. After you run Lighthouse, it will give you a score for various dimensions: Performance, Accessibility, Best Practices, and SEO. Additionally, you can measure test coverage. This will be done every time you run the tests via maven mvn test , using the Jacoco tool. After looking over the metrics, pick one metric to improve (Performance, Accessibility, Best Practices, SEO, or Code Coverage). The Lighthouse reports will give you some suggestions as to how to improve a score. The only requirements are that your change should affect the metric's score, and that the change should involve a commit to the repo. HINT: Because of this, you might want to avoid trying to change the performance score. First, open an issue in the https://github.com/CMU-313/Teedy/issues to declare what aspect of Teedy you will be improving. You should look through existing issues, if any, to avoid duplicates. In the issue description, mention the current score you observed and the warning that you are targeting. ~~Tag the issue with one or more of the existing labels as appropriate, add it to milestone \"HW1\", and~~ assign yourself (do this by commenting \"I would like to work on this please!\"). In your own fork, create a feature branch, implement the change, test it out locally, and commit your changes. Your commit message(s) must clearly describe what's changing. Once you are satisfied, open a pull request in the parent repository. The PR should link the issue that you previously opened (e.g. using the \"resolve(s)\" keyword), summarize the changes, and describe how much the score improved by due to your change. After you have completed this task, we will ask you to reflect on the nature of metrics. To do this, you will answer the following questions about metrics, specifically in the context of Teedy. You should focus your answers for each of these questions on the metric that you chose to improve. What properties do we care about, and how do we measure them? What is being measured? Does it (to what degree) capture the thing you care about? What are its limitations? How should this metric be incorporated into process? Check in gate? Once a month? Etc. What are potentially negative side effects or incentives?","title":"Specification"},{"location":"assignments/HW1/#deliverables-and-deadlines","text":"There are three (3) deliverables and one (1) deadline for this homework. Individual Component -- 100 points -- due Thursday, September 9th, 23:59 Create an issue in the parent repository, which must: Mention the metric you are targeting. Mention the current metric scores. Be assigned to yourself. ~~Be tagged with at least one appropriate label. Be associated with the HW1 milestone.~~ Create a pull request in the parent repository, which must: Reference the issue created above. Describe the fix and improvement to the score. Answer the following questions on Gradescope about the metric you chose: - What properties do we care about, and how do we measure it? - What is being measured? Does it (to what degree) capture the thing you care about? What are its limitations? - How should it be incorporated into process? Check in gate? Once a month? Etc. - What are potentially negative side effects or incentives?","title":"Deliverables and Deadlines"},{"location":"assignments/HW1/#grading","text":"This homework is worth 100 points. Running the project, making the change, and committing it properly constitutes 50 points (50%), and the reflection questions constitutes 50 points (50%). To receive full credit for the group component, we expect: The correct use of tools and technology, including Git, GitHub, and Lighthouse. Answers to the questions that demonstrate understanding of the benefits and limitations of software metrics, specifically in the context of Teedy. This analysis should go beyond superficial statements, mere descriptions, and truisms, which ties specifically to the context of this assignment.","title":"Grading"},{"location":"assignments/HW2/","text":"Homework 2: Learning the Codebase Learning Goals Learn about the design and implementation of an existing software project that you will build upon this semester Collaborate with your teammates to design and implement a small feature addition or modification to that software project Practice version control and development best practices within the context of a group assignment Specification Now that you have onboarded to 17-313, setup your development environment, and met your team, upper management has tasked you with building a graduate student admissions system over the course of the semester (described below). Rather than creating a new admissions system from scratch, management has decided that you and your team will repurpose and adapt an existing document management system, Teedy. Beyond being a pretty good document management platform, Teedy provides complex features that you expect will be useful, like tagging, workflows, and fine-grained permissions and ACLs (access control lists). Despite its considerable functionality, Teedy is still missing many of the basic features that you expect to find in the most rudimentary of admissions systems and needs changes to be better fit for purpose. Your goal in this homework assignment is to dig into the implementation of Teedy to better understand how it's designed and fits together, and to learn more about its associated technologies. To that end, your team has been tasked with implementing a small feature change or addition that requires you to make a change in each of the following layers of Teedy's stack: Java backend: docs-core/src/main/java/com/sismics/docs REST middleware: docs-web/src/main/java/com/sismics/docs/rest Angular.js frontend: docs-web/src/main/webapp Team and GitHub repository. You will be working on your team repository for this project. First, collectively choose a team name. Your team name should be unique, pronounceable, short, and something you would be proud to shout in your team cheer on the streets of Pittsburgh in the presence of small, impressionable, multi-lingual children. Then, go to the link below to set up your team: once you provide your team name, it will automatically create a repository for your team. WARNING: After you join a team, you cannot change teams! Make sure that only one of you creates the team, and make sure that the remaining teammates join the right team. After you have read the above warning, go here to set up your team: https://classroom.github.com/a/ZjoPJFMC Use the team repository for all your development, and be sure to use good development practices, including keeping your commits cohesive and your commit messages informative. We will be grading you on how well you follow the process we used for HW1 and the recitation activity: - create issues for feature improvements or bug-fixes, - when creating issue, assign team members and tag with appropriate labels, - and create a pull request and reference the issue to merge the changes. In this project, however, you will not create an issue or a pull request in the parent repository, but in your team repository, like what you did in the recitation 1. It is not acceptable for one person to commit all work after synchronizing through other means. This will factor into your grade. The code, testing, and documentation deliverables below will be taken by snapshotting your repository at the deadline. Project Description CMU has over 7,000 graduate students. The university uses a software system to manage the graduate student admissions process, including collecting relevant information from applicants, accepting recommendation letters from third-parties, showing this information to the admissions committee and accepting ratings and commentary from the admissions committee to support decisions, and notifying applicants of the decision. This system is old, clunky, and universally disliked. You and your team are developing a new system. Requirements for this new system remain a bit vague, and we are looking for you to put your own expereince and creativity into developing a better solution. Your point of contact insists primarily that the new system needs to be \"less garbage\" than the current system. When pressed for details, she elaborates that faculty complain that the current system makes it too difficult to evaluate the applicants; students (applicants) and their letter writers complain that the system is hard to use. Everyone finds configuration and management difficult. Deadlines and deliverables This homework has two (2) deadlines and two (3) deliverables. The deliverables are described below: Planning---Team (due Thursday, Sept 22, 23:59) -- 20 points You must create an issue in your group's Teedy repository that: - Describes the new feature (or change to an existing feature) that you will implement for this assignment. The feature/change does not need to be large, but it must require code changes across the entire Teedy stack. The goal of this assignment is not to maximize value for your project client but instead to learn as much as possible about the existing codebase. - Roughly outlines the changes that need to be made at each level in the Teedy stack and specifies which team member(s) are responsible for implementing those changes. - If you are unsure about your planned changes, ask for feedback on your issue from a member of the course staff! Implementation:--Team (due Thursday, Sept 22, 23:59) -- 80 points You should follow best practices for collaborative development such as using feature branches, pull requests, and code review (e.g., tackling each layer of the stack in a separate PR). Specifically your team should collaborate on this feature by committing changes to a branch named for the feature you are implementing. Every member of your team must contribute to the implementation. One way we will evalute this is that each team member must have at least one commit as a part of the solution. Failure to do so will result in a significant penalty to your grade. You must commit all of your changes to the main branch of your repository before the homework deadline. Unlike the previous assignment, you should not submit your changes to the parent Teedy repository. Group Presentation:--Team (due Tuesday, Sept 27, 23:59, presentation uploaded to gradescope) -- 30 points During the Week 5 recitation slot, your group will give a short 10-minute presentation describing your changes (e.g., what you changed, how you changed the code, how you tested your changes) and what you learned about the codebase. Each team member should be prepared to describe the changes they made. In order to make the deadline fair across all sections, the presentation should be submitted to gradescope by Tuesday Sept 27th, 11:59pm. Individual Reflection:--Team (due Tuesday, Sept 27, 23:59) -- 30 points You will answer individual reflection questions on Gradescope (HW2 Individual Reflection). We will ask you to describe the changes that you personally made, how you made those changes, and what you would do differently if given more time. Extra credit:--Team (due Tuesday, Sept 27, 23:59) -- 8 pts (5% of the overall assignment grade) Getting to know your colleagues in a friendly context can often lead to more effective collaboration; healthy teams often get lunch together, for example. To incentivize this, we will give your team 5% extra credit for this assignment if you meet for a team outside of a working session. You might want to eat together, or go out for boba. If someone on your team is not feeling well, you may also do a virtual activity such as an online gaming session (drawasaurus?) or social \"zoom lunch\". On the 17-313 Slack workspace, create a new private channel (name it team-<teamname> ) that includes all your team members and the two TAs who are your team mentors (these are the same TAs that run your recitation---if you are unsure, ask on #general ). Share the photo or screenshot of your team activity on the slack channel with your TA mentors to receive the 5% extra credit. You can also use this slack channel for subsequent project-team related discussions or specialized Q&A with your TA mentors for the rest of the semester. Grading You will be graded as a team, with an individual component. This homework is worth 160 points, with an additional 8 points of extra credit available.","title":"Homework 2"},{"location":"assignments/HW2/#homework-2-learning-the-codebase","text":"","title":"Homework 2: Learning the Codebase"},{"location":"assignments/HW2/#learning-goals","text":"Learn about the design and implementation of an existing software project that you will build upon this semester Collaborate with your teammates to design and implement a small feature addition or modification to that software project Practice version control and development best practices within the context of a group assignment","title":"Learning Goals"},{"location":"assignments/HW2/#specification","text":"Now that you have onboarded to 17-313, setup your development environment, and met your team, upper management has tasked you with building a graduate student admissions system over the course of the semester (described below). Rather than creating a new admissions system from scratch, management has decided that you and your team will repurpose and adapt an existing document management system, Teedy. Beyond being a pretty good document management platform, Teedy provides complex features that you expect will be useful, like tagging, workflows, and fine-grained permissions and ACLs (access control lists). Despite its considerable functionality, Teedy is still missing many of the basic features that you expect to find in the most rudimentary of admissions systems and needs changes to be better fit for purpose. Your goal in this homework assignment is to dig into the implementation of Teedy to better understand how it's designed and fits together, and to learn more about its associated technologies. To that end, your team has been tasked with implementing a small feature change or addition that requires you to make a change in each of the following layers of Teedy's stack: Java backend: docs-core/src/main/java/com/sismics/docs REST middleware: docs-web/src/main/java/com/sismics/docs/rest Angular.js frontend: docs-web/src/main/webapp","title":"Specification"},{"location":"assignments/HW2/#team-and-github-repository","text":"You will be working on your team repository for this project. First, collectively choose a team name. Your team name should be unique, pronounceable, short, and something you would be proud to shout in your team cheer on the streets of Pittsburgh in the presence of small, impressionable, multi-lingual children. Then, go to the link below to set up your team: once you provide your team name, it will automatically create a repository for your team. WARNING: After you join a team, you cannot change teams! Make sure that only one of you creates the team, and make sure that the remaining teammates join the right team. After you have read the above warning, go here to set up your team: https://classroom.github.com/a/ZjoPJFMC Use the team repository for all your development, and be sure to use good development practices, including keeping your commits cohesive and your commit messages informative. We will be grading you on how well you follow the process we used for HW1 and the recitation activity: - create issues for feature improvements or bug-fixes, - when creating issue, assign team members and tag with appropriate labels, - and create a pull request and reference the issue to merge the changes. In this project, however, you will not create an issue or a pull request in the parent repository, but in your team repository, like what you did in the recitation 1. It is not acceptable for one person to commit all work after synchronizing through other means. This will factor into your grade. The code, testing, and documentation deliverables below will be taken by snapshotting your repository at the deadline.","title":"Team and GitHub repository."},{"location":"assignments/HW2/#project-description","text":"CMU has over 7,000 graduate students. The university uses a software system to manage the graduate student admissions process, including collecting relevant information from applicants, accepting recommendation letters from third-parties, showing this information to the admissions committee and accepting ratings and commentary from the admissions committee to support decisions, and notifying applicants of the decision. This system is old, clunky, and universally disliked. You and your team are developing a new system. Requirements for this new system remain a bit vague, and we are looking for you to put your own expereince and creativity into developing a better solution. Your point of contact insists primarily that the new system needs to be \"less garbage\" than the current system. When pressed for details, she elaborates that faculty complain that the current system makes it too difficult to evaluate the applicants; students (applicants) and their letter writers complain that the system is hard to use. Everyone finds configuration and management difficult.","title":"Project Description"},{"location":"assignments/HW2/#deadlines-and-deliverables","text":"This homework has two (2) deadlines and two (3) deliverables. The deliverables are described below:","title":"Deadlines and deliverables"},{"location":"assignments/HW2/#planning-team-due-thursday-sept-22-2359-20-points","text":"You must create an issue in your group's Teedy repository that: - Describes the new feature (or change to an existing feature) that you will implement for this assignment. The feature/change does not need to be large, but it must require code changes across the entire Teedy stack. The goal of this assignment is not to maximize value for your project client but instead to learn as much as possible about the existing codebase. - Roughly outlines the changes that need to be made at each level in the Teedy stack and specifies which team member(s) are responsible for implementing those changes. - If you are unsure about your planned changes, ask for feedback on your issue from a member of the course staff!","title":"Planning---Team (due Thursday, Sept 22, 23:59) -- 20 points"},{"location":"assignments/HW2/#implementation-team-due-thursday-sept-22-2359-80-points","text":"You should follow best practices for collaborative development such as using feature branches, pull requests, and code review (e.g., tackling each layer of the stack in a separate PR). Specifically your team should collaborate on this feature by committing changes to a branch named for the feature you are implementing. Every member of your team must contribute to the implementation. One way we will evalute this is that each team member must have at least one commit as a part of the solution. Failure to do so will result in a significant penalty to your grade. You must commit all of your changes to the main branch of your repository before the homework deadline. Unlike the previous assignment, you should not submit your changes to the parent Teedy repository.","title":"Implementation:--Team (due Thursday, Sept 22, 23:59)  -- 80 points"},{"location":"assignments/HW2/#group-presentation-team-due-tuesday-sept-27-2359-presentation-uploaded-to-gradescope-30-points","text":"During the Week 5 recitation slot, your group will give a short 10-minute presentation describing your changes (e.g., what you changed, how you changed the code, how you tested your changes) and what you learned about the codebase. Each team member should be prepared to describe the changes they made. In order to make the deadline fair across all sections, the presentation should be submitted to gradescope by Tuesday Sept 27th, 11:59pm.","title":"Group Presentation:--Team (due Tuesday, Sept 27, 23:59, presentation uploaded to gradescope)  -- 30 points"},{"location":"assignments/HW2/#individual-reflection-team-due-tuesday-sept-27-2359-30-points","text":"You will answer individual reflection questions on Gradescope (HW2 Individual Reflection). We will ask you to describe the changes that you personally made, how you made those changes, and what you would do differently if given more time.","title":"Individual Reflection:--Team (due Tuesday, Sept 27, 23:59)  -- 30 points"},{"location":"assignments/HW2/#extra-credit-team-due-tuesday-sept-27-2359-8-pts-5-of-the-overall-assignment-grade","text":"Getting to know your colleagues in a friendly context can often lead to more effective collaboration; healthy teams often get lunch together, for example. To incentivize this, we will give your team 5% extra credit for this assignment if you meet for a team outside of a working session. You might want to eat together, or go out for boba. If someone on your team is not feeling well, you may also do a virtual activity such as an online gaming session (drawasaurus?) or social \"zoom lunch\". On the 17-313 Slack workspace, create a new private channel (name it team-<teamname> ) that includes all your team members and the two TAs who are your team mentors (these are the same TAs that run your recitation---if you are unsure, ask on #general ). Share the photo or screenshot of your team activity on the slack channel with your TA mentors to receive the 5% extra credit. You can also use this slack channel for subsequent project-team related discussions or specialized Q&A with your TA mentors for the rest of the semester.","title":"Extra credit:--Team (due Tuesday, Sept 27, 23:59)  -- 8 pts (5% of the overall assignment grade)"},{"location":"assignments/HW2/#grading","text":"You will be graded as a team, with an individual component. This homework is worth 160 points, with an additional 8 points of extra credit available.","title":"Grading"},{"location":"assignments/HW3/","text":"Homework 3: Teamwork Learning Goals Plan and schedule projects in terms of tasks, milestones, and time estimations, and re-plan as required Make initial decisions on a process, and reflect on experience with the process Effectively coordinate among team members and conduct effective team meetings Meaningfully reflect on the experience of working in teams Collaborate in development projects using Git and engage in good software writing practices Practice getting to know a pre-existing code base and developing new features for it using previously unfamiliar technology Project context In HW2, you familiarized yourself with Teedy; You set up your development environment and workflow, and explored the full layers of Teedy by implementing a small feature change or addition. Now, we want to take a more serious step to build the graduate student admission management system. You and your team are beginning to sketch out and implement a replacement admissions system. You start with a simplified workflow that you hope to build from later: assume a single academic program, and that applicants upload single resumes to apply. Resumes are assessed by 3--4 reviewers along several dimensions (like \"skills\", \"experience\", \"GPA\", etc), along with additional notes/commentary. This information is used to inform admissions committee discussions and decisions. Your first goal is to decide which feature you should/will implement to improve the system. Have an initial brainstorming meeting, and come up with a feature that touches all three layers (Java Backend, REST middleware, and Angular.js frontend). Here are some of the features that teams implemented in the past: A dashboard or pane for reviewer assignment and management. A form for reviewers to enter and score candidates along various (custom/admissions-specific) directions, to be saved and possibly aggregated across multiple reviewers. A dashboard or pane for aggregating and displaying statistics, like average review score per candidate; average review score per reviewer; or other aggregate statistics for the applicant pool. Then, you will do so, over the course of a 2-week sprint, while establishing and following a good software engineering process, including appropriate git flow and testing of the eventual feature. Specifically, this entails: Do an initial sprint planning meeting. Assess your feature options and choose which one you will implement first, for this assignment. Construct your backlog (decompose the task, roughly estimate the time required for the sub-tasks, identify dependencies, and plan the implementation accordingly). The selected feature should (1) be able to be divided into at least N (the number of team members in your team) sub-features, and (2) require you to make changes in each of the three layers of Teedy's stack. Perform a 2-week sprint to implement and user test the feature in question. You will likely not have time to produce a perfect feature, but you should be able to produce a reasonable prototype. Throughout the project, track your time investment, synchronize tasks with your team, and regularly update the plan. Take meeting minutes and track how you divide up the work. Document your code/feature, user testing approach, and process and decision-making. It should be easy for the TA to run and test your feature within Teedy. We encourage you to read and follow the Team Policy , which has suggestions for effective group work in a course setting (you may have to adapt some of these suggestions for collaborating on a software project, but you may still find the structure helpful). Plan carefully to decide which features to develop, and in what order, and then start writing code effectively as a team. Process You should create a new public team repository for this project. https://classroom.github.com/a/i2efqHx6 You can still import the changes you have made for HW2 into your new repository. Be sure to use good development practices. We will be grading you on how well you follow the process we covered in the lectures and recitations: - use a kanban board to manage the workflow, - create issues for feature improvements or bug-fixes, - when creating issues, assign team members and tag them with appropriate labels, - create a pull request and reference the issue to merge the changes, - provide feedback to pull requests, - document design decisions and implemented functionalities, - write automated tests for the features you implement, - and use GitHub Actions for continuous integration (CI). Like in HW2, you will not create an issue or a pull request in the parent repository, but in your team repository. It is not acceptable for one person to commit all work after synchronizing through other means. This will factor into your grade. The code, testing, and documentation deliverables below will be taken by snapshotting your repository at the deadline. Deadlines and deliverables This homework has three (3) deadlines and four (4) deliverables. The first deadline (Thursday, September 29, 23:59) is for an initial planning document and backlog . The second deadline (Thursday, October 6, 23:59) is for the technical artifacts . The third deadline (Thursday, October 13, 23:59) is for two (2) reflection tasks . We intentionally separated these deadlines to ensure upfront documentation of the planning process and to give you time to reflect. Of course, you are still encouraged to start developing before the second deadline and reflecting before the third. (1) Initial plan (due Thursday, September 29, 23:59) -- 60 points An initial technical/sprint plan and backlog, with justification. First, indicate which feature you chose to implement first, and why. Then, present your initial backlog for the sprint (from before you started implementing; you will discuss changes/replanning that happened in a later deliverable). You are encouraged to include supporting evidence for all of your decisions and estimates (i.e., an explanation for how you arrived at that decision/value). To grade your team, we will be looking for the following information to be documented in your team's GitHub Projects board : a set of overall tasks necessary to implement the feature (these tasks together should result in a feature, but each task is a small step along the way to the feature), estimated effort for each task, dependencies among tasks, which you plan to tackle for the first sprint to build the core functionality, task assignments for team members for the initial sprint planning, acceptance criteria (how do you tell when this task is done - you can think about how you will test this feature). An initial process plan. On Gradescope, you will describe the process you are planning to follow. By process, we mean how you are going to develop the system and which steps you are going to follow, rather than a technical design model of the software. Specifically, we are interested in how you are planning to collaborate (e.g., communication channels, meetings and their frequency, pull requests or dropbox) and in what overall development activities you plan (e.g., how much design, which quality assurance steps, how shall parts be integrated). We will not grade the accuracy of your prediction or how well you stuck with your initial plan; instead, we will focus on how well you decomposed the problem and justified your original plan, how you responded to changes in the replanning, and how well you analyze and reflect on your experience (see below). 2) Code artifacts (due Thursday, October 6, 23:59) -- 60 points We will take a snapshot of the implementation from your team's GitHub repository at the deadline. Your repository should include the implementation of the system, automated tests for the new feature, and a documentation of how to use and user test your new feature (indicate where this documentation is found from the top-level README.md file). You should follow best practices for collaborative development such as using feature branches, pull requests, and code review (e.g., tackling each layer of the stack in a separate PR). Specifically your team should collaborate on this feature by committing changes to a branch named for the feature you are implementing. GitHub Actions should be enabled. It is reasonable to have failures in feature branches, but you should do your best to make your main branch build consistently pass. Adhere to good coding practices. For example, your code should have a clear structure, be reasonably modularized, use appropriate variable names, and be documented. We expect you to write a set of automated tests that demonstrates the functionalities you implemented (according to your acceptance criteria from the initial planning). We will look at the commit, issue, and pull request history. Every member of your team must contribute to the implementation: each team member must have at least one commit as a part of the solution. Failure to do so will result in a significant penalty to your grade. You must commit all of your changes to the main branch of your repository before the homework deadline. Unlike HW01, you should not submit your changes to the parent Teedy repository. (3) Reflection -- Team (due Thursday, October 13, 23:59) -- 60 points After coding is complete, reflect on your experience as a team. Again, we look for honest reflection, which will likely include reflection on failures. We will not grade whether you predicted the effort correctly, but rather what you learned from the process. There will be 5 reflection questions on Gradescope: Actual Schedule: Document the actual schedule, including the tasks you actually performed and the actual amount of time each took. Ideally, you will have kept your schedule up-to-date throughout the project, simplifying this task. Schedule Deviations: Reflect on the differences between the initial and the final schedule. Which milestones were predicted correctly? What was re-planned? Were there any activities you didn't plan for initially or that you had to drop in the end? What were the reasons for the changes? Could they have been foreseen with better planning? Process: Reflect on the process you initially planned to follow, and the process you actually followed. Was the process adequate? Did you skip steps or adopt additional techniques during the project? What challenges did you face? How could the process be improved if you had to do another, similar project? How might you have to change the process to adapt to a different type of project? Team Experience: Reflect on your experience working as a team. What worked well? Were team meetings efficient? How well, and through which processes, did you communicate? What needs improvement? Were there any teamwork challenges you resolved as the project progressed? Meeting Minutes: Attach all meeting minutes kept throughout the project, which should include information about the agenda/topics discussed, decisions made, and work assignments. Recording results of meetings can be onerous; you must explicitly rotate this responsibility among the members of your team (and indicate who took which minutes). One of the main purposes of this homework is to encourage in-depth analysis of the reasons for good or bad time estimation, scheduling, and teamwork coordination. Doing poorly in these is not unusual (as numerous reports from real-life projects show). Therefore, we will not evaluate how well (or badly) the project went, but instead how well you understood the reasons [why]{.underline} the project went as it did, and what lessons you drew from your experience to inform your future work. A good reflection document will include concrete statements about lessons learned, with clear supporting evidence, such as examples, to support the claims. It is a good idea to reference your meeting protocols to support your claims and provide examples. For example, \"We could have communicated better.\" is weakly supported. One could strengthen it with examples from the development experience as follows: \"One source of [defects/development slowdown/quality problems] was the integration of components A and B, because the API for A was not well-understood by the developer of B...In the future, we might try to use [such-and-such a process] for clearly documenting and communicating such design decisions, rather than [the process we did follow/failed to follow].\" Being able to communicate effectively is an important software engineering skill. As such, your reflection should be well-written and easy to read. Be sure to leave time after writing for revision and proofreading. There are many convenient tools for collaborative text editing; the course staff used Google Docs for this homework document. (4) Reflection -- Individual (due Thursday, October 13, 23:59) -- 60 points You will answer individual reflection questions on Gradescope (HW3 Individual Reflection). We will ask you to reflect on the process, scheduling, and teamwork. (Note that this is due at the same time as the team reflection.) Separate from the reflection done as a group, each team member should individually reflect on (1) the process, (2) the scheduling, and (3) the teamwork, and connect this project experience with their previous experience (preferably experience from a non-academic setting, but experience from class projects is also fine). You do not need to answer any specific questions, but the following questions may guide possible content for the reflection: How does this project experience align with your previous experiences? What was similar? What was different? What did you personally learn from this project's development process? Is there something you are planning to do differently in your future projects? Similar to the team reflection task, we will grade the quality and depth of your reflection. Grading You will be graded as a team, with an individual component. This homework is worth 240 points. We will grade you based on the learning goals listed above. The initial planning constitutes 60 points (25%), the technical artifacts and adherence to the process constitute 60 points (25%), the team reflection constitutes 60 points (25%), and the individual reflection constitutes 60 points (25%). To receive full credit for the planning, we expect: A sensible justification for the feature you selected to implement in this sprint. A backlog that includes tasks, dependencies, time estimates, and assignments, as described above. An outline of the process steps to be adopted in this project. To receive full credit for the technical artifacts, we expect: A running prototype implementation. Automated test cases for the implemented functionalities. GitHub Actions set up and used for builds and automated tests. Reasonable documentation of the new feature. Reasonable code structure and style, including documentation where appropriate. Coherent commits of reasonable size with meaningful commit messages by all team members. Reasonable quality of issues, pull requests, and comments. Reasonable QA/user testing for the new feature. To receive full credit on reflection, we expect: A detailed, well written, and well structured reflection on the issues listed above. A comparison between the planned and the actual schedule. An analysis beyond mere descriptions and superficial statements, including supporting evidence for claims, that reflects on the causes of deviations, conflicts, and so forth, or your own experience. Inclusion of meeting minutes(s) that adequately demonstrate the meeting process. Notes This homework (except for the individual reflection) is to be done in your assigned teams. You are highly encouraged to openly discuss all team issues that may arise in the process of working within the teams. After this homework, we will perform a peer-feedback survey to identify any common issues that we will then address in class. If severe issues occur reach out earlier to the course staff.","title":"Homework 3"},{"location":"assignments/HW3/#homework-3-teamwork","text":"","title":"Homework 3: Teamwork"},{"location":"assignments/HW3/#learning-goals","text":"Plan and schedule projects in terms of tasks, milestones, and time estimations, and re-plan as required Make initial decisions on a process, and reflect on experience with the process Effectively coordinate among team members and conduct effective team meetings Meaningfully reflect on the experience of working in teams Collaborate in development projects using Git and engage in good software writing practices Practice getting to know a pre-existing code base and developing new features for it using previously unfamiliar technology","title":"Learning Goals"},{"location":"assignments/HW3/#project-context","text":"In HW2, you familiarized yourself with Teedy; You set up your development environment and workflow, and explored the full layers of Teedy by implementing a small feature change or addition. Now, we want to take a more serious step to build the graduate student admission management system. You and your team are beginning to sketch out and implement a replacement admissions system. You start with a simplified workflow that you hope to build from later: assume a single academic program, and that applicants upload single resumes to apply. Resumes are assessed by 3--4 reviewers along several dimensions (like \"skills\", \"experience\", \"GPA\", etc), along with additional notes/commentary. This information is used to inform admissions committee discussions and decisions. Your first goal is to decide which feature you should/will implement to improve the system. Have an initial brainstorming meeting, and come up with a feature that touches all three layers (Java Backend, REST middleware, and Angular.js frontend). Here are some of the features that teams implemented in the past: A dashboard or pane for reviewer assignment and management. A form for reviewers to enter and score candidates along various (custom/admissions-specific) directions, to be saved and possibly aggregated across multiple reviewers. A dashboard or pane for aggregating and displaying statistics, like average review score per candidate; average review score per reviewer; or other aggregate statistics for the applicant pool. Then, you will do so, over the course of a 2-week sprint, while establishing and following a good software engineering process, including appropriate git flow and testing of the eventual feature. Specifically, this entails: Do an initial sprint planning meeting. Assess your feature options and choose which one you will implement first, for this assignment. Construct your backlog (decompose the task, roughly estimate the time required for the sub-tasks, identify dependencies, and plan the implementation accordingly). The selected feature should (1) be able to be divided into at least N (the number of team members in your team) sub-features, and (2) require you to make changes in each of the three layers of Teedy's stack. Perform a 2-week sprint to implement and user test the feature in question. You will likely not have time to produce a perfect feature, but you should be able to produce a reasonable prototype. Throughout the project, track your time investment, synchronize tasks with your team, and regularly update the plan. Take meeting minutes and track how you divide up the work. Document your code/feature, user testing approach, and process and decision-making. It should be easy for the TA to run and test your feature within Teedy. We encourage you to read and follow the Team Policy , which has suggestions for effective group work in a course setting (you may have to adapt some of these suggestions for collaborating on a software project, but you may still find the structure helpful). Plan carefully to decide which features to develop, and in what order, and then start writing code effectively as a team.","title":"Project context"},{"location":"assignments/HW3/#process","text":"You should create a new public team repository for this project. https://classroom.github.com/a/i2efqHx6 You can still import the changes you have made for HW2 into your new repository. Be sure to use good development practices. We will be grading you on how well you follow the process we covered in the lectures and recitations: - use a kanban board to manage the workflow, - create issues for feature improvements or bug-fixes, - when creating issues, assign team members and tag them with appropriate labels, - create a pull request and reference the issue to merge the changes, - provide feedback to pull requests, - document design decisions and implemented functionalities, - write automated tests for the features you implement, - and use GitHub Actions for continuous integration (CI). Like in HW2, you will not create an issue or a pull request in the parent repository, but in your team repository. It is not acceptable for one person to commit all work after synchronizing through other means. This will factor into your grade. The code, testing, and documentation deliverables below will be taken by snapshotting your repository at the deadline.","title":"Process"},{"location":"assignments/HW3/#deadlines-and-deliverables","text":"This homework has three (3) deadlines and four (4) deliverables. The first deadline (Thursday, September 29, 23:59) is for an initial planning document and backlog . The second deadline (Thursday, October 6, 23:59) is for the technical artifacts . The third deadline (Thursday, October 13, 23:59) is for two (2) reflection tasks . We intentionally separated these deadlines to ensure upfront documentation of the planning process and to give you time to reflect. Of course, you are still encouraged to start developing before the second deadline and reflecting before the third.","title":"Deadlines and deliverables"},{"location":"assignments/HW3/#1-initial-plan-due-thursday-september-29-2359-60-points","text":"An initial technical/sprint plan and backlog, with justification. First, indicate which feature you chose to implement first, and why. Then, present your initial backlog for the sprint (from before you started implementing; you will discuss changes/replanning that happened in a later deliverable). You are encouraged to include supporting evidence for all of your decisions and estimates (i.e., an explanation for how you arrived at that decision/value). To grade your team, we will be looking for the following information to be documented in your team's GitHub Projects board : a set of overall tasks necessary to implement the feature (these tasks together should result in a feature, but each task is a small step along the way to the feature), estimated effort for each task, dependencies among tasks, which you plan to tackle for the first sprint to build the core functionality, task assignments for team members for the initial sprint planning, acceptance criteria (how do you tell when this task is done - you can think about how you will test this feature). An initial process plan. On Gradescope, you will describe the process you are planning to follow. By process, we mean how you are going to develop the system and which steps you are going to follow, rather than a technical design model of the software. Specifically, we are interested in how you are planning to collaborate (e.g., communication channels, meetings and their frequency, pull requests or dropbox) and in what overall development activities you plan (e.g., how much design, which quality assurance steps, how shall parts be integrated). We will not grade the accuracy of your prediction or how well you stuck with your initial plan; instead, we will focus on how well you decomposed the problem and justified your original plan, how you responded to changes in the replanning, and how well you analyze and reflect on your experience (see below).","title":"(1) Initial plan (due Thursday, September 29, 23:59) -- 60 points"},{"location":"assignments/HW3/#2-code-artifacts-due-thursday-october-6-2359-60-points","text":"We will take a snapshot of the implementation from your team's GitHub repository at the deadline. Your repository should include the implementation of the system, automated tests for the new feature, and a documentation of how to use and user test your new feature (indicate where this documentation is found from the top-level README.md file). You should follow best practices for collaborative development such as using feature branches, pull requests, and code review (e.g., tackling each layer of the stack in a separate PR). Specifically your team should collaborate on this feature by committing changes to a branch named for the feature you are implementing. GitHub Actions should be enabled. It is reasonable to have failures in feature branches, but you should do your best to make your main branch build consistently pass. Adhere to good coding practices. For example, your code should have a clear structure, be reasonably modularized, use appropriate variable names, and be documented. We expect you to write a set of automated tests that demonstrates the functionalities you implemented (according to your acceptance criteria from the initial planning). We will look at the commit, issue, and pull request history. Every member of your team must contribute to the implementation: each team member must have at least one commit as a part of the solution. Failure to do so will result in a significant penalty to your grade. You must commit all of your changes to the main branch of your repository before the homework deadline. Unlike HW01, you should not submit your changes to the parent Teedy repository.","title":"2) Code artifacts (due Thursday, October 6, 23:59) -- 60 points"},{"location":"assignments/HW3/#3-reflection-team-due-thursday-october-13-2359-60-points","text":"After coding is complete, reflect on your experience as a team. Again, we look for honest reflection, which will likely include reflection on failures. We will not grade whether you predicted the effort correctly, but rather what you learned from the process. There will be 5 reflection questions on Gradescope: Actual Schedule: Document the actual schedule, including the tasks you actually performed and the actual amount of time each took. Ideally, you will have kept your schedule up-to-date throughout the project, simplifying this task. Schedule Deviations: Reflect on the differences between the initial and the final schedule. Which milestones were predicted correctly? What was re-planned? Were there any activities you didn't plan for initially or that you had to drop in the end? What were the reasons for the changes? Could they have been foreseen with better planning? Process: Reflect on the process you initially planned to follow, and the process you actually followed. Was the process adequate? Did you skip steps or adopt additional techniques during the project? What challenges did you face? How could the process be improved if you had to do another, similar project? How might you have to change the process to adapt to a different type of project? Team Experience: Reflect on your experience working as a team. What worked well? Were team meetings efficient? How well, and through which processes, did you communicate? What needs improvement? Were there any teamwork challenges you resolved as the project progressed? Meeting Minutes: Attach all meeting minutes kept throughout the project, which should include information about the agenda/topics discussed, decisions made, and work assignments. Recording results of meetings can be onerous; you must explicitly rotate this responsibility among the members of your team (and indicate who took which minutes). One of the main purposes of this homework is to encourage in-depth analysis of the reasons for good or bad time estimation, scheduling, and teamwork coordination. Doing poorly in these is not unusual (as numerous reports from real-life projects show). Therefore, we will not evaluate how well (or badly) the project went, but instead how well you understood the reasons [why]{.underline} the project went as it did, and what lessons you drew from your experience to inform your future work. A good reflection document will include concrete statements about lessons learned, with clear supporting evidence, such as examples, to support the claims. It is a good idea to reference your meeting protocols to support your claims and provide examples. For example, \"We could have communicated better.\" is weakly supported. One could strengthen it with examples from the development experience as follows: \"One source of [defects/development slowdown/quality problems] was the integration of components A and B, because the API for A was not well-understood by the developer of B...In the future, we might try to use [such-and-such a process] for clearly documenting and communicating such design decisions, rather than [the process we did follow/failed to follow].\" Being able to communicate effectively is an important software engineering skill. As such, your reflection should be well-written and easy to read. Be sure to leave time after writing for revision and proofreading. There are many convenient tools for collaborative text editing; the course staff used Google Docs for this homework document.","title":"(3) Reflection -- Team (due Thursday, October 13, 23:59) -- 60 points"},{"location":"assignments/HW3/#4-reflection-individual-due-thursday-october-13-2359-60-points","text":"You will answer individual reflection questions on Gradescope (HW3 Individual Reflection). We will ask you to reflect on the process, scheduling, and teamwork. (Note that this is due at the same time as the team reflection.) Separate from the reflection done as a group, each team member should individually reflect on (1) the process, (2) the scheduling, and (3) the teamwork, and connect this project experience with their previous experience (preferably experience from a non-academic setting, but experience from class projects is also fine). You do not need to answer any specific questions, but the following questions may guide possible content for the reflection: How does this project experience align with your previous experiences? What was similar? What was different? What did you personally learn from this project's development process? Is there something you are planning to do differently in your future projects? Similar to the team reflection task, we will grade the quality and depth of your reflection.","title":"(4) Reflection -- Individual (due Thursday, October 13, 23:59) -- 60 points"},{"location":"assignments/HW3/#grading","text":"You will be graded as a team, with an individual component. This homework is worth 240 points. We will grade you based on the learning goals listed above. The initial planning constitutes 60 points (25%), the technical artifacts and adherence to the process constitute 60 points (25%), the team reflection constitutes 60 points (25%), and the individual reflection constitutes 60 points (25%). To receive full credit for the planning, we expect: A sensible justification for the feature you selected to implement in this sprint. A backlog that includes tasks, dependencies, time estimates, and assignments, as described above. An outline of the process steps to be adopted in this project. To receive full credit for the technical artifacts, we expect: A running prototype implementation. Automated test cases for the implemented functionalities. GitHub Actions set up and used for builds and automated tests. Reasonable documentation of the new feature. Reasonable code structure and style, including documentation where appropriate. Coherent commits of reasonable size with meaningful commit messages by all team members. Reasonable quality of issues, pull requests, and comments. Reasonable QA/user testing for the new feature. To receive full credit on reflection, we expect: A detailed, well written, and well structured reflection on the issues listed above. A comparison between the planned and the actual schedule. An analysis beyond mere descriptions and superficial statements, including supporting evidence for claims, that reflects on the causes of deviations, conflicts, and so forth, or your own experience. Inclusion of meeting minutes(s) that adequately demonstrate the meeting process.","title":"Grading"},{"location":"assignments/HW3/#notes","text":"This homework (except for the individual reflection) is to be done in your assigned teams. You are highly encouraged to openly discuss all team issues that may arise in the process of working within the teams. After this homework, we will perform a peer-feedback survey to identify any common issues that we will then address in class. If severe issues occur reach out earlier to the course staff.","title":"Notes"},{"location":"assignments/HW4/","text":"Homework 4: Microservices Learning Goals Design, implement, and test a microservice. Decide whether and when to use microservices, understanding benefits and limitations. Write an effective design document. Assess and describe choices between alternative architectural designs. Engage meaningfully with questions of engineering ethics. Project context You and your team are hard at work on the new graduate admissions system for CMU. During your most recent sprint planning meeting, your CMU technical contact bursts into the room, shouting, \u201cMachine learning! Microservices!\u201d When pressed, your newly buzzword-enamored boss explains: the population of applicants is too large, and increasing annually. Admissions is taking too much time and effort. Fortunately, CMU has been collecting student performance data. They continue: \u201cCan\u2019t your team make use of all that fancy new machine learning to help predict which applicants are more likely to succeed, helping the admissions process along? And since we\u2019re checking off buzzwords, can\u2019t you implement it as a microservice?\u201d You are correctly skeptical about the effort required to pivot the product in this new direction, but fortunately the somewhat disconnected microservice demand gives you a way to explore the idea without requiring a major up front change in the existing codebase. Instead, you\u2019ll (1) develop this potential feature in isolation by training a machine learning model that predicts potential applicant success and deploying it as a microservice, and then (2) reason about, document, and choose between alternative designs that would allow you to integrate it into the existing codebase. Finally, you will (3) individually consider the ethical implications of the feature, and what questions you truly need to ask in QA to satisfy possible ethical concerns. Starter code, data, and repository Create a new team repository using this repository as a template. The starter code includes: an example Flask-based app in the app/ directory. Use this as a template to build and deploy the microservice. You may wish to use this article and this repository as resources on building and saving a scikit-learn model, and then deploying it using Flask. MAKE SURE to read the README.MD of the repository to learn about and use Pipenv, as it will allow for hassle-free collaboration. a default model under app/ , which can be explored with the Jupyter notebook ( model_build.ipnyb ). You will need to create a better-performing model as a part of this homework. We provide you with a (synthetic) historical dataset (as a CSV file) of student performance (this is an augmented version of the dataset found here ), and a (bad) model trained over it. Start by exploring the data, to understand what information is available. Student performance is described by their grades (G1, G2, and G3), where G3 is the final year grade, the target performance metric. Grades are on a scale of 0-20; 20 is the best. CMU considers a high-quality student one with a G3 grade of 15 or higher. The existing model in the repository is very simple. Once you have familiarized yourself with the dataset, explore this model using whatever means you think are appropriate and determine in which ways you don\u2019t believe it to be suitable. Based on what you learn in this exploratory step, you should train a new model and build a deployable microservice. You should evaluate your new model, and should explain how this model (overall) performs better than the baseline model, and any ways in which your model performs worse than the baseline model. Plan some testing, perform that testing on your microservice endpoints, and document it. You should create a test suite using, for example, pytest , and update your GitHub Actions workflow to run the test suite. This starter code uses arguments from the query string (specifically age, health, and absences) to query the model. This can/should be expanded or replaced as a part of your implementation (note that the API also accepts JSON requests). Note that the default Flask service in the starter code should be run, and is accessible, on port 80. Feel free to change as needed. Deadlines and deliverables This homework has three (3) deadlines and four (4) deliverables. The first deadline (Tuesday, November 1st) is a checkpoint to make sure you and your team are succeeding at building your microservice-based ML model. The second deadline (Tuesday, Nov 8th) is for the complete trained model deployable as a microservice, and a design document explaining how you would integrate the new feature into your existing codebase. The third deadline (Thursday, Nov 10th) is for one (1) individual document making an ethical argument about the feature. (1) API Design, Documentation, and Testing (due Tuesday, Nov 1st 11:59 PM) -- 50 points For this checkpoint, you and your team should make sure that all of you are working on the same versions of Python and Python packages. You should use Swagger to define and document the REST API for your microservice, and write a set of API tests that encode the expected functionality of your API (via pytest ). Note that, for this deadline, the API does not need to be functional; it is only required that you create placeholder REST API endpoints that you can use to write your tests. NOTE: We expect your tests to be failing at this point. The implementation that allows the tests to pass will be written later. The deliverable for this checkpoints are: a PDF and YAML version of your Swagger documentation. Note that you can create a PDF of your Swagger documentation via the Print Preview function of your browser. a set of API tests within your GitHub repository. Consider both expected behavior and edge cases. (2) Implementation (due Tuesday, Nov 8th, 23:59) -- 30 points The deliverable for this task is a documented technical artifact; submit a link of your GitHub repository to the Gradescope assignment. This should include: a complete implementation that includes the API endpoints that you previously defined, and returns a prediction using your trained model. an updated README that clearly and concisely describes features used to training your model, and how your retrained the model performs better than the baseline model. (3) Architectural Design Document (due Tuesday, Nov 8th, 23:59) -- 50 points Once you have demoed this feature, and shown that it can provide value, you are now faced with a decision about how to implement a long term solution here. You have at least several options including but not limited to: Rewrite the feature in Java and incorporate it into the monolith Keep python demo microservice implementation, and deploy as a seperate service, integrating with your existing monolith via REST API Refactor part or all of the existing monolith into a microservices based architecture Your deliverable for this part is a design document describing the feature and how it should be integrated into the system as a microservice. Submit this to the assignment on Gradescope. (NOTE: you will not have to actually implement this decision, for this or any subsequent homework in this class. You might consider implementation effort as part of your tradeoff analysis, but you should not let speculation about your workload in this class influence your decision.) The design document must (1) concisely describe the feature, (2) make and justify a decision on how the implementation should be done, including considered alternatives and tradeoffs, and using/referencing suitable diagrams where relevant to support your argument: Feature description. This should be concise (< 0.5 pages). Decision and architectural justification for how to integrate the feature into the system. This must include at least: A concise, prioritized list of the overall quality requirements you considered in arguing for the integration of the feature into the system (<0.5 pages, soft limit). You may consider and reference the requirements you elicited during HW3 as appropriate. Rank them in decreasing order of importance. This allows readers to quickly understand what requirements you were designing for. A design decision with a textual justification of your design. (~2 pages, soft limit, including alternatives and tradeoffs, below) Outline and argue for a particular implementation choice as to how the feature should be integrated into the overall system architecturally. Justify your design decisions, including why your design is adequate for the quality attributes important to this system, and what assumptions you made in your design. Considered alternatives and tradeoffs. The design decision and justification must include description of considered alternatives, the tradeoffs they present, and why they were rejected. Tradeoffs must involve (but are not limited to) quality attributes that will be affected by the alternative. Justify such arguments with reference to appropriate diagrams (this provides traceability) and concrete examples, as appropriate. On diagrams. The design document must include both diagrams and text. Diagrams should involve suitable architectural views; must include a legend; and should involve appropriate levels of abstraction for the components in the diagram. If necessary, use color/shape/text to differentiate between types of components and connectors. You may find it appropriate to merge more than one view into a single diagram. If you do this, you must be explicit about what views you are merging, and why. Otherwise, diagrams should clearly represent legitimate architectural views. Make sure that multiple views of the architecture are consistent with each other and the links are clear; if necessary provide a mapping in additional text. Documenting Software Architectures: Views and Beyond, Second Edition is a useful book on creating architecture documentation. It is available (for free) as an e-book from the CMU library web site. If you use it, treat it as reference material; do not plan to read major parts of it. Drawing diagrams is easier with the right software. Consider tools like draw.io (free, online, and collaborative), Dia, OmniGraffle, MS Visio, or even just the drawing editor of Google Docs. Google Slides will also likely work for this purpose. Pictures of whiteboard drawings are also acceptable, if clearly readable. Additional Hints: The design document task is easy to underestimate both in terms of time needed and in terms of difficulty designing meaningful and useful descriptions. While it is easy to create a superficial solution, a good solution will likely require significant thinking, discussion, and iteration. Feel free to seek feedback from the course staff on your solution before submission. It may take several iterations to get your architectural views right. Appoint someone to track the accuracy and completeness of architectural representations throughout this assignment. Do not just divide up the views among your team members and assume they show everything needed. You only need to submit the final designs/documents, not intermediate steps on the process of getting there. As additional reference material, Software Architecture in Practice, Third Edition is a book on software architecture that is available (for free) as an e-book from the CMU library web site. You may wish to review appropriate sections within Part Two to help find appropriate tactics, techniques you can use in your design to promote particular quality attributes. Note that the book is not a reading assignment and you should not try to read it thoroughly. Instead, use it as reference material and select particular bits of advice that are relevant to your situation. (4) Ethical Discussion (due Thursday, Nov 10th, 23:59) -- 30 points This is an individual component. Note: this is not an open-ended reflection document like those we have requested in previous assignments. You must engage with the ethical questions at hand. For this deliverable, we will ask you to think about potential ethical concerns with the technology that you are proposing to implement. You should consider the ethical implications from the perspective of all potential stakeholders. You might find it helpful to consider the questions we considered in class: Does the software respect the humanity of the users? Does my software amplify positive behavior, or negative behavior for both users and society at large Could the software\u2019s quality impact the humanity of others? You should generate a list of potential ethical concerns for this system you are considering implementing. For each concern, you should assess the risk of that concern (Remember risk is how likely it is to happen, and how bad would the outcomes be). After assessing the risk, you should consider ways to address the ethical concern. For each concern, you should consider potential actions that could help address this concern, and safeguard against potential problems. The deliverable for this task is a document (soft limit 3 pages), submitted to Gradescope that: Reasons about ethical concerns when implementing an ML feature to help decide which students to accept to CMU. An assessment of the risk for each ethical concern A discussion of how to address each ethical concern. A criteria that can be used to evaluate if the intervention described in part (c) is successful. Grading You will be graded as a team, with an individual component. This homework is worth 160 points. We will grade you based on the learning goals listed above. To receive full credit for the checkpoint, we expect: That you have written Swagger Docs with reasonable API endpoints. That you have automated, runnable tests that exercise your API endpoints according to your Swagger Docs. Remember, they don't need to pass at the checkpoint, but they should pass by the end. To receive full credit for the technical artifacts, we expect: A working artifact that outperforms the baseline model A discussion of how the new model was evaluated, and some evidence that it outperforms the baseline model The checkpoint tests now passing with a correct implementation To receive full credit on the design document, we expect: A concise, accurate feature description. A list of the quality requirements you considered, ranked in decreasing order of importance. Appropriate use of at least two diagrams to support your design argument. A clear decision with an accurate description of how you think the feature should be integrated into the current system (diagrams and text). Someone else should be able to read this description and understand where to start, implementation-wise. Do not say only \u201cIf X, then I\u2019d choose design #1; otherwise, I\u2019d choose design #2.\u201d In the real world, decisions must be made on the basis of incomplete information, with an understanding that sometimes the wrong decision gets made. You can say what information you wish you had in order to better-inform your decision. A good, substantive argument in favor of the design choice you made. This must include explicit description and consideration of alternatives, the substantiated (connected to quality attributes and other concerns) tradeoffs they afford, and reasons that you decided to reject them. These should be supported with technical arguments. A thorough discussion of the tradeoffs among the options. If there are any situations in which your choice was the wrong one, what would those situations look like, and how would you know (after the fact) that this was the case? To receive full credit on the individual ethical reflection, we expect: A discussion of ethical concerns that considers a wide variety of stakeholders That you can reason about potential ethical concerns before the emerge Thoughtful consideration of what it would take to address these concerns Troubleshooting and FAQ Cannot install pipenv Your python or pip installer might be outdated. Reinstall a specific version of python via homebrew. You would need homebrew. We recommend using homebrew. brew install python@3.8 Reinstall/update pip3 python -m pip3 install --upgrade pip OR pip3 install --upgrade pip Installed pipenv, but cannot install packages from pipenv It might be that some packages are not installed. We have updated the starter code's pipfile here (as of 10/31/2022), so that it explicilty indicates which version of which packages you need (otherwise pip would just used the version currently installed on your machine). You can just copy and paste the new Pipfile into your own, and pipenv install again Installed packages, but doesn't show up on jupyter notebook? It's probably that jupyter's python path isn't set properly in the kernel config file. The kernel needs to be created within the pipenv shell to pick up the right path. Troubleshooting Make sure ipykernel package is installed within your pipenv. If not, run pipenv install ipykernel Enter the virtual shell via: pipenv shell In the shell, create a new kernel via: python -m ipykernel install --user --name=my-virtualenv-name where my-virtualenv-name can be the name of your kernel/venv name. Now, launch the jupyter notebook jupyter notebook Finally, in your notebook, Kernel -> Change Kernel. Your kernel should now be an option. source: pythonanywhere.com I ran the flask app, but 404 errors constantly show up Make sure you're starting your flask app within the app directory. At the return statement of your /predict endpoint, np.asscalar is actually outdated and does not work. This is a mistake on our part. You can get the same result using np.ndarray.item . How can I test endpoints if I need URLs to call them? Will GH actions work with the localhost URL and endpoints? You don't need the url. You can search on google \"pytest flask api post request\" and get these results . Feel free to use any, but this resource (first from the search result) seems to be helpful. You can also use the starter code for reference to see how the existing made a call to the client!","title":"Homework 4"},{"location":"assignments/HW4/#homework-4-microservices","text":"","title":"Homework 4: Microservices"},{"location":"assignments/HW4/#learning-goals","text":"Design, implement, and test a microservice. Decide whether and when to use microservices, understanding benefits and limitations. Write an effective design document. Assess and describe choices between alternative architectural designs. Engage meaningfully with questions of engineering ethics.","title":"Learning Goals"},{"location":"assignments/HW4/#project-context","text":"You and your team are hard at work on the new graduate admissions system for CMU. During your most recent sprint planning meeting, your CMU technical contact bursts into the room, shouting, \u201cMachine learning! Microservices!\u201d When pressed, your newly buzzword-enamored boss explains: the population of applicants is too large, and increasing annually. Admissions is taking too much time and effort. Fortunately, CMU has been collecting student performance data. They continue: \u201cCan\u2019t your team make use of all that fancy new machine learning to help predict which applicants are more likely to succeed, helping the admissions process along? And since we\u2019re checking off buzzwords, can\u2019t you implement it as a microservice?\u201d You are correctly skeptical about the effort required to pivot the product in this new direction, but fortunately the somewhat disconnected microservice demand gives you a way to explore the idea without requiring a major up front change in the existing codebase. Instead, you\u2019ll (1) develop this potential feature in isolation by training a machine learning model that predicts potential applicant success and deploying it as a microservice, and then (2) reason about, document, and choose between alternative designs that would allow you to integrate it into the existing codebase. Finally, you will (3) individually consider the ethical implications of the feature, and what questions you truly need to ask in QA to satisfy possible ethical concerns.","title":"Project context"},{"location":"assignments/HW4/#starter-code-data-and-repository","text":"Create a new team repository using this repository as a template. The starter code includes: an example Flask-based app in the app/ directory. Use this as a template to build and deploy the microservice. You may wish to use this article and this repository as resources on building and saving a scikit-learn model, and then deploying it using Flask. MAKE SURE to read the README.MD of the repository to learn about and use Pipenv, as it will allow for hassle-free collaboration. a default model under app/ , which can be explored with the Jupyter notebook ( model_build.ipnyb ). You will need to create a better-performing model as a part of this homework. We provide you with a (synthetic) historical dataset (as a CSV file) of student performance (this is an augmented version of the dataset found here ), and a (bad) model trained over it. Start by exploring the data, to understand what information is available. Student performance is described by their grades (G1, G2, and G3), where G3 is the final year grade, the target performance metric. Grades are on a scale of 0-20; 20 is the best. CMU considers a high-quality student one with a G3 grade of 15 or higher. The existing model in the repository is very simple. Once you have familiarized yourself with the dataset, explore this model using whatever means you think are appropriate and determine in which ways you don\u2019t believe it to be suitable. Based on what you learn in this exploratory step, you should train a new model and build a deployable microservice. You should evaluate your new model, and should explain how this model (overall) performs better than the baseline model, and any ways in which your model performs worse than the baseline model. Plan some testing, perform that testing on your microservice endpoints, and document it. You should create a test suite using, for example, pytest , and update your GitHub Actions workflow to run the test suite. This starter code uses arguments from the query string (specifically age, health, and absences) to query the model. This can/should be expanded or replaced as a part of your implementation (note that the API also accepts JSON requests). Note that the default Flask service in the starter code should be run, and is accessible, on port 80. Feel free to change as needed.","title":"Starter code, data, and repository"},{"location":"assignments/HW4/#deadlines-and-deliverables","text":"This homework has three (3) deadlines and four (4) deliverables. The first deadline (Tuesday, November 1st) is a checkpoint to make sure you and your team are succeeding at building your microservice-based ML model. The second deadline (Tuesday, Nov 8th) is for the complete trained model deployable as a microservice, and a design document explaining how you would integrate the new feature into your existing codebase. The third deadline (Thursday, Nov 10th) is for one (1) individual document making an ethical argument about the feature.","title":"Deadlines and deliverables"},{"location":"assignments/HW4/#1-api-design-documentation-and-testing-due-tuesday-nov-1st-1159-pm-50-points","text":"For this checkpoint, you and your team should make sure that all of you are working on the same versions of Python and Python packages. You should use Swagger to define and document the REST API for your microservice, and write a set of API tests that encode the expected functionality of your API (via pytest ). Note that, for this deadline, the API does not need to be functional; it is only required that you create placeholder REST API endpoints that you can use to write your tests. NOTE: We expect your tests to be failing at this point. The implementation that allows the tests to pass will be written later. The deliverable for this checkpoints are: a PDF and YAML version of your Swagger documentation. Note that you can create a PDF of your Swagger documentation via the Print Preview function of your browser. a set of API tests within your GitHub repository. Consider both expected behavior and edge cases.","title":"(1) API Design, Documentation, and Testing (due Tuesday, Nov 1st 11:59 PM) -- 50 points"},{"location":"assignments/HW4/#2-implementation-due-tuesday-nov-8th-2359-30-points","text":"The deliverable for this task is a documented technical artifact; submit a link of your GitHub repository to the Gradescope assignment. This should include: a complete implementation that includes the API endpoints that you previously defined, and returns a prediction using your trained model. an updated README that clearly and concisely describes features used to training your model, and how your retrained the model performs better than the baseline model.","title":"(2) Implementation (due Tuesday, Nov 8th, 23:59) -- 30 points"},{"location":"assignments/HW4/#3-architectural-design-document-due-tuesday-nov-8th-2359-50-points","text":"Once you have demoed this feature, and shown that it can provide value, you are now faced with a decision about how to implement a long term solution here. You have at least several options including but not limited to: Rewrite the feature in Java and incorporate it into the monolith Keep python demo microservice implementation, and deploy as a seperate service, integrating with your existing monolith via REST API Refactor part or all of the existing monolith into a microservices based architecture Your deliverable for this part is a design document describing the feature and how it should be integrated into the system as a microservice. Submit this to the assignment on Gradescope. (NOTE: you will not have to actually implement this decision, for this or any subsequent homework in this class. You might consider implementation effort as part of your tradeoff analysis, but you should not let speculation about your workload in this class influence your decision.) The design document must (1) concisely describe the feature, (2) make and justify a decision on how the implementation should be done, including considered alternatives and tradeoffs, and using/referencing suitable diagrams where relevant to support your argument: Feature description. This should be concise (< 0.5 pages). Decision and architectural justification for how to integrate the feature into the system. This must include at least: A concise, prioritized list of the overall quality requirements you considered in arguing for the integration of the feature into the system (<0.5 pages, soft limit). You may consider and reference the requirements you elicited during HW3 as appropriate. Rank them in decreasing order of importance. This allows readers to quickly understand what requirements you were designing for. A design decision with a textual justification of your design. (~2 pages, soft limit, including alternatives and tradeoffs, below) Outline and argue for a particular implementation choice as to how the feature should be integrated into the overall system architecturally. Justify your design decisions, including why your design is adequate for the quality attributes important to this system, and what assumptions you made in your design. Considered alternatives and tradeoffs. The design decision and justification must include description of considered alternatives, the tradeoffs they present, and why they were rejected. Tradeoffs must involve (but are not limited to) quality attributes that will be affected by the alternative. Justify such arguments with reference to appropriate diagrams (this provides traceability) and concrete examples, as appropriate. On diagrams. The design document must include both diagrams and text. Diagrams should involve suitable architectural views; must include a legend; and should involve appropriate levels of abstraction for the components in the diagram. If necessary, use color/shape/text to differentiate between types of components and connectors. You may find it appropriate to merge more than one view into a single diagram. If you do this, you must be explicit about what views you are merging, and why. Otherwise, diagrams should clearly represent legitimate architectural views. Make sure that multiple views of the architecture are consistent with each other and the links are clear; if necessary provide a mapping in additional text. Documenting Software Architectures: Views and Beyond, Second Edition is a useful book on creating architecture documentation. It is available (for free) as an e-book from the CMU library web site. If you use it, treat it as reference material; do not plan to read major parts of it. Drawing diagrams is easier with the right software. Consider tools like draw.io (free, online, and collaborative), Dia, OmniGraffle, MS Visio, or even just the drawing editor of Google Docs. Google Slides will also likely work for this purpose. Pictures of whiteboard drawings are also acceptable, if clearly readable. Additional Hints: The design document task is easy to underestimate both in terms of time needed and in terms of difficulty designing meaningful and useful descriptions. While it is easy to create a superficial solution, a good solution will likely require significant thinking, discussion, and iteration. Feel free to seek feedback from the course staff on your solution before submission. It may take several iterations to get your architectural views right. Appoint someone to track the accuracy and completeness of architectural representations throughout this assignment. Do not just divide up the views among your team members and assume they show everything needed. You only need to submit the final designs/documents, not intermediate steps on the process of getting there. As additional reference material, Software Architecture in Practice, Third Edition is a book on software architecture that is available (for free) as an e-book from the CMU library web site. You may wish to review appropriate sections within Part Two to help find appropriate tactics, techniques you can use in your design to promote particular quality attributes. Note that the book is not a reading assignment and you should not try to read it thoroughly. Instead, use it as reference material and select particular bits of advice that are relevant to your situation.","title":"(3) Architectural Design Document (due Tuesday, Nov 8th, 23:59) -- 50 points"},{"location":"assignments/HW4/#4-ethical-discussion-due-thursday-nov-10th-2359-30-points","text":"This is an individual component. Note: this is not an open-ended reflection document like those we have requested in previous assignments. You must engage with the ethical questions at hand. For this deliverable, we will ask you to think about potential ethical concerns with the technology that you are proposing to implement. You should consider the ethical implications from the perspective of all potential stakeholders. You might find it helpful to consider the questions we considered in class: Does the software respect the humanity of the users? Does my software amplify positive behavior, or negative behavior for both users and society at large Could the software\u2019s quality impact the humanity of others? You should generate a list of potential ethical concerns for this system you are considering implementing. For each concern, you should assess the risk of that concern (Remember risk is how likely it is to happen, and how bad would the outcomes be). After assessing the risk, you should consider ways to address the ethical concern. For each concern, you should consider potential actions that could help address this concern, and safeguard against potential problems. The deliverable for this task is a document (soft limit 3 pages), submitted to Gradescope that: Reasons about ethical concerns when implementing an ML feature to help decide which students to accept to CMU. An assessment of the risk for each ethical concern A discussion of how to address each ethical concern. A criteria that can be used to evaluate if the intervention described in part (c) is successful.","title":"(4) Ethical Discussion (due Thursday, Nov 10th, 23:59) -- 30 points"},{"location":"assignments/HW4/#grading","text":"You will be graded as a team, with an individual component. This homework is worth 160 points. We will grade you based on the learning goals listed above. To receive full credit for the checkpoint, we expect: That you have written Swagger Docs with reasonable API endpoints. That you have automated, runnable tests that exercise your API endpoints according to your Swagger Docs. Remember, they don't need to pass at the checkpoint, but they should pass by the end. To receive full credit for the technical artifacts, we expect: A working artifact that outperforms the baseline model A discussion of how the new model was evaluated, and some evidence that it outperforms the baseline model The checkpoint tests now passing with a correct implementation To receive full credit on the design document, we expect: A concise, accurate feature description. A list of the quality requirements you considered, ranked in decreasing order of importance. Appropriate use of at least two diagrams to support your design argument. A clear decision with an accurate description of how you think the feature should be integrated into the current system (diagrams and text). Someone else should be able to read this description and understand where to start, implementation-wise. Do not say only \u201cIf X, then I\u2019d choose design #1; otherwise, I\u2019d choose design #2.\u201d In the real world, decisions must be made on the basis of incomplete information, with an understanding that sometimes the wrong decision gets made. You can say what information you wish you had in order to better-inform your decision. A good, substantive argument in favor of the design choice you made. This must include explicit description and consideration of alternatives, the substantiated (connected to quality attributes and other concerns) tradeoffs they afford, and reasons that you decided to reject them. These should be supported with technical arguments. A thorough discussion of the tradeoffs among the options. If there are any situations in which your choice was the wrong one, what would those situations look like, and how would you know (after the fact) that this was the case? To receive full credit on the individual ethical reflection, we expect: A discussion of ethical concerns that considers a wide variety of stakeholders That you can reason about potential ethical concerns before the emerge Thoughtful consideration of what it would take to address these concerns","title":"Grading"},{"location":"assignments/HW4/#troubleshooting-and-faq","text":"","title":"Troubleshooting and FAQ"},{"location":"assignments/HW4/#cannot-install-pipenv","text":"Your python or pip installer might be outdated. Reinstall a specific version of python via homebrew. You would need homebrew. We recommend using homebrew. brew install python@3.8 Reinstall/update pip3 python -m pip3 install --upgrade pip OR pip3 install --upgrade pip","title":"Cannot install pipenv"},{"location":"assignments/HW4/#installed-pipenv-but-cannot-install-packages-from-pipenv","text":"It might be that some packages are not installed. We have updated the starter code's pipfile here (as of 10/31/2022), so that it explicilty indicates which version of which packages you need (otherwise pip would just used the version currently installed on your machine). You can just copy and paste the new Pipfile into your own, and pipenv install again","title":"Installed pipenv, but cannot install packages from pipenv"},{"location":"assignments/HW4/#installed-packages-but-doesnt-show-up-on-jupyter-notebook","text":"It's probably that jupyter's python path isn't set properly in the kernel config file. The kernel needs to be created within the pipenv shell to pick up the right path. Troubleshooting Make sure ipykernel package is installed within your pipenv. If not, run pipenv install ipykernel Enter the virtual shell via: pipenv shell In the shell, create a new kernel via: python -m ipykernel install --user --name=my-virtualenv-name where my-virtualenv-name can be the name of your kernel/venv name. Now, launch the jupyter notebook jupyter notebook Finally, in your notebook, Kernel -> Change Kernel. Your kernel should now be an option. source: pythonanywhere.com","title":"Installed packages, but doesn't show up on jupyter notebook?"},{"location":"assignments/HW4/#i-ran-the-flask-app-but-404-errors-constantly-show-up","text":"Make sure you're starting your flask app within the app directory. At the return statement of your /predict endpoint, np.asscalar is actually outdated and does not work. This is a mistake on our part. You can get the same result using np.ndarray.item .","title":"I ran the flask app, but 404 errors constantly show up"},{"location":"assignments/HW4/#how-can-i-test-endpoints-if-i-need-urls-to-call-them-will-gh-actions-work-with-the-localhost-url-and-endpoints","text":"You don't need the url. You can search on google \"pytest flask api post request\" and get these results . Feel free to use any, but this resource (first from the search result) seems to be helpful. You can also use the starter code for reference to see how the existing made a call to the client!","title":"How can I test endpoints if I need URLs to call them? Will GH actions work with the localhost URL and endpoints?"},{"location":"assignments/HW5/","text":"Homework 5: Quality Assurance for the People Learning Goals Gain hands-on experience with analysis tools, including setting up, customizing, and using them. Practically assess and compare the costs and benefits of existing static and dynamic bug-finding tools. Develop a plan to integrate and roll out tools in development practice. Explain the predictions of a Machine Learning Model, and reason about their implications. Project Context and Tasks Quality Assurance is a critical part of software development. Although you have been testing your new graduate admissions system this whole time, you are now setting out to establish a sustained QA practice that can be used moving forward as you iterate over and continue to improve your system. Your CTO has assigned you the task of evaluating existing tools and practices beyond unit testing, and producing a report on (A) the cost/benefit tradeoffs and risks of several tools and processes and (B) how they might fit in development practice. Static and Dynamic Analysis First, you will evaluate and choose between a set of analysis tools, integrate it into your build/deployment pipeline, and document your decisions/process by way of a design document/RFC. For the purposes of this RFC, you must identify and experiment with at least N potential static and dynamic analysis tools that are applicable to your system, where N is the size of your group. We provide a starter list below; you should include at least one static analysis and one dynamic analysis tools, and at least one tool must be taken from either a Google search or from the Awesome Static/Dynamic Analysis page (that is, cannot otherwise be listed in the bulleted list). You can create a new team repository by following the link for your team, which will clone the Teedy code automatically: Create Assignment with Github Classroom Apply one or more of the tools to your project. You may also apply it to one or more other programs if you wish to assess it in different contexts. Consider and experiment with the types of customization that are appropriate or necessary for this tool, both a priori (before they can be used in your project) and possibly over time. Assess the strengths and weaknesses of each tool/technique, both quantitatively and qualitatively. You might consider issues like, but not limited to: what types of problems are you hoping your tooling will catch? What types of problems does a particular tool catch? What types of customization are possible or necessary? How can/should this tool be integrated into a development process? Are there many false positives? False negatives? True positive reports about things you don't care about? The deliverable for this part, at a high level, is a Design Document/RFC that explains and justifies the tooling you propose to incorporate into your process, and how you propose to do so. This decision should be feature- and data-driven, and should consider usability and process questions like how and when the tooling will be applied, and by whom. See below for more details. NOTE: you do not need to integrate ALL N tools into your repo, but you should integrate at least (1) tool so that it runs via CI, and have one commit on which it was run. You should reference this commit in your design document Starter list of Tools Teedy has a Java backend and an AngularJS (JavaScript) frontend. Below are non-exhaustive lists of analysis tools that are available for both Java and JavaScript. Others are available. Awesome Static Analysis page/repo and Awesome Dynamic Analysis page/repo have extensive listings of available static and dynamic analysis tools for a pretty hefty list of programming languages, including Java. Some of the tools have GitHub Actions workflows on GitHub Marketplace ; use your Googling skills, and see what you find! Java Static analysis: - Checkstyle , a tool for checking Java source code for adherence to a code standard. - SpotBugs , a fork of FindBugs that can spot over 400 bug patterns Dynamic analysis: - Pitest , a mutation testing system for Java. - YourKit , commercial Java profiler (15 days trial) JavaScript eslint is a widely used linter in modern JavaScript packages. flow is a static type checker for JavaScript. ML Model Assessment In the last homework assignment, you created a Machine Learning model. In fact, after your success with HW4, your team has started collecing data in production, and the new data for your ML service goes well beyond the data you used for testing. Therefore, your CTO is seriously considering adding it into your product. However, before announcing it as a feature, she wants to ensure that your team has a deep understanding of how the ML model is working, as well as that it is tested with respect to any concerns that may have surfaced previously. For this task, your team is tasked with writing a data-driven report for your CTO. You should evaluate the model, test outcomes, present your findings, and discuss them. Your first task is to present a data-driven analysis of the predictions that your model is making. You will do this using the LIME tool we have previously looked at in class: https://github.com/marcotcr/lime Run this tool on your model, and collect data on how the model is making predictions. You should use this data to report on the behavior of the ML recommendation system. Here, when you run the tool, remember to use the more complete production data that your team has collected, in the place of the previous limited training data. You can find the updated data here: Production Data The data-driven analysis will allow your company to ensure that the ML is working properly. However, you are also concerned with fairness. You should also include in your report a data-driven analysis of the fairness of your algorithm. To analyze the fairness, you should remember the fairness discussion we had in class, based on this tool: ML Discrimination . Then, consider two of the fairness approaches we discussed in class, and compare them. Finally, you report should include a recommendation if you want to use the ML, scrap it, or make specific improvements before rolling it out. Specifically your report should include the following information: Data-driven analysis of the predictions the model is making. Any concerns you have about the quality of the predictions in light of this data. Any features in the data you are concerned about from a fairness perspective. HINT: you might want to consult your last homework when considering this. A data-driven analysis of the interplay between these features and your ML model. There are various ways to do this, but a simple approach might consider the following: Distribution of this feature in your dataset. Distribution of this feature in your accepted and rejected recommendation populations Relationship between this feature and your false positives and false negatives. Based on this data, you should consider what is the fairness strategy that you are trying to achieve. You may use two of the fairness strategies we considered in class, or define your own. If you define a new fairness strategy, you should describe it, and present why you think it is a better fit than any of the existing strategies for this product. If you are not happy with the performance of the system, based on the data you have collected, you should do the following: Report on what aspects of the system you are unhappy with Iterate your model 1 iteration, and see if you can improve its performance. Most likely, this will NOT be enough to fix it, but your goal in this assignment is to learn enough to make a reasonable estimate of the effort needed to fix the model. Make an estimate of how long it will take to bring the model up to acceptable performance. This can be a \"T-Shirt\" estimate (e.g., S/M/L/XL) but it should also include completion criteria. This will look like specific thresholds that your model should achieve before you would be comfortable shipping it as a part of your product. At the end of this report, make a recommendation to your CTO. This recommendation should be one of the following: It is good enough to use now, we should ship it. It is not good enough to ship, but we have a plan to improve it We don't feel comfortable shipping this feature, we should scrap it. Deadlines and Deliverables This homework has one (1) deadline and two (2) deliverables. The deadline ( Friday, Nov 18 ) is for all the deliverables: the static analysis design doc, and the report on the ML model. Part A: Static Analysis - Group (due Nov 18) - 50 points (50%) The deliverable for this part is a Design Document/RFC that provides (1) a justified explanation for which tool(s) you think the project should use moving forward, and (2) how it shall be integrated into your process (you must recommend at least one tool, even if it's with reservations). This latter point should address both technical (e.g., at what point in the development/deployment process shall it be integrated? What sorts of customization or configuration will you be using?) and social issues (e.g., how will you incentivize the change?), as applicable. The justification should be based on your experiences running the tools and, as much as possible, be grounded in data about, for example, tool usability, output, and customizability. Be sure the RFC also explains/justifies the alternative tools (or process options, if pertinent) that have been rejected. To receive full credit, you must consider at least N total tool options in your RFC, where N is the size of your team. The document should also contain other relevant sections for a Design Document/RFC for this type of (development process) feature. Are there open questions? Issues you consider out of scope? Drawbacks of the proposed process/tooling that you are accepting for some (good) reason? Etc. That is: make sure it's a good/complete design document! NOTE: in your PDF submitted to gradescope, you should explictly reference at least one commit on which your tool has been run in your repo. Submit the Design Document as a single PDF to Gradescope. Part B: ML Explainability -- Group (due Nov 18) -- 50 points (50%) For this deliverable, you will be collecting data, and writing a report. The report should include the data you collect as well as your interpretation of the data. First, you should collect data by running LIME on your ML model from the last homework (use the model you have in the fall-22-hw4 repository), with the new data. You should present the results of this as data in your report. Then, you will interpret the data to explain why your machine learning model is making predictions. This information should include the features that provide the most predictive power. You should also evaluate your machine learning model considering fairness issues. You will evaluate the performance of your model with a specific target fairness strategy in mind, and if you are unhappy with the fairness of the model, you will come up with thresholds that you feel the model must meet before you would feel comfortable using it. Based on your findings, you should recommend one of three options. You might feel that the model is good enough to deploy as is, you might recommend specific changes before you deploy, or you might recommend it not be deployed at all. Submit this report as a PDF via Gradescope.","title":"Homework 5"},{"location":"assignments/HW5/#homework-5-quality-assurance-for-the-people","text":"","title":"Homework 5: Quality Assurance for the People"},{"location":"assignments/HW5/#learning-goals","text":"Gain hands-on experience with analysis tools, including setting up, customizing, and using them. Practically assess and compare the costs and benefits of existing static and dynamic bug-finding tools. Develop a plan to integrate and roll out tools in development practice. Explain the predictions of a Machine Learning Model, and reason about their implications.","title":"Learning Goals"},{"location":"assignments/HW5/#project-context-and-tasks","text":"Quality Assurance is a critical part of software development. Although you have been testing your new graduate admissions system this whole time, you are now setting out to establish a sustained QA practice that can be used moving forward as you iterate over and continue to improve your system. Your CTO has assigned you the task of evaluating existing tools and practices beyond unit testing, and producing a report on (A) the cost/benefit tradeoffs and risks of several tools and processes and (B) how they might fit in development practice.","title":"Project Context and Tasks"},{"location":"assignments/HW5/#static-and-dynamic-analysis","text":"First, you will evaluate and choose between a set of analysis tools, integrate it into your build/deployment pipeline, and document your decisions/process by way of a design document/RFC. For the purposes of this RFC, you must identify and experiment with at least N potential static and dynamic analysis tools that are applicable to your system, where N is the size of your group. We provide a starter list below; you should include at least one static analysis and one dynamic analysis tools, and at least one tool must be taken from either a Google search or from the Awesome Static/Dynamic Analysis page (that is, cannot otherwise be listed in the bulleted list). You can create a new team repository by following the link for your team, which will clone the Teedy code automatically: Create Assignment with Github Classroom Apply one or more of the tools to your project. You may also apply it to one or more other programs if you wish to assess it in different contexts. Consider and experiment with the types of customization that are appropriate or necessary for this tool, both a priori (before they can be used in your project) and possibly over time. Assess the strengths and weaknesses of each tool/technique, both quantitatively and qualitatively. You might consider issues like, but not limited to: what types of problems are you hoping your tooling will catch? What types of problems does a particular tool catch? What types of customization are possible or necessary? How can/should this tool be integrated into a development process? Are there many false positives? False negatives? True positive reports about things you don't care about? The deliverable for this part, at a high level, is a Design Document/RFC that explains and justifies the tooling you propose to incorporate into your process, and how you propose to do so. This decision should be feature- and data-driven, and should consider usability and process questions like how and when the tooling will be applied, and by whom. See below for more details. NOTE: you do not need to integrate ALL N tools into your repo, but you should integrate at least (1) tool so that it runs via CI, and have one commit on which it was run. You should reference this commit in your design document","title":"Static and Dynamic Analysis"},{"location":"assignments/HW5/#starter-list-of-tools","text":"Teedy has a Java backend and an AngularJS (JavaScript) frontend. Below are non-exhaustive lists of analysis tools that are available for both Java and JavaScript. Others are available. Awesome Static Analysis page/repo and Awesome Dynamic Analysis page/repo have extensive listings of available static and dynamic analysis tools for a pretty hefty list of programming languages, including Java. Some of the tools have GitHub Actions workflows on GitHub Marketplace ; use your Googling skills, and see what you find! Java Static analysis: - Checkstyle , a tool for checking Java source code for adherence to a code standard. - SpotBugs , a fork of FindBugs that can spot over 400 bug patterns Dynamic analysis: - Pitest , a mutation testing system for Java. - YourKit , commercial Java profiler (15 days trial) JavaScript eslint is a widely used linter in modern JavaScript packages. flow is a static type checker for JavaScript.","title":"Starter list of Tools"},{"location":"assignments/HW5/#ml-model-assessment","text":"In the last homework assignment, you created a Machine Learning model. In fact, after your success with HW4, your team has started collecing data in production, and the new data for your ML service goes well beyond the data you used for testing. Therefore, your CTO is seriously considering adding it into your product. However, before announcing it as a feature, she wants to ensure that your team has a deep understanding of how the ML model is working, as well as that it is tested with respect to any concerns that may have surfaced previously. For this task, your team is tasked with writing a data-driven report for your CTO. You should evaluate the model, test outcomes, present your findings, and discuss them. Your first task is to present a data-driven analysis of the predictions that your model is making. You will do this using the LIME tool we have previously looked at in class: https://github.com/marcotcr/lime Run this tool on your model, and collect data on how the model is making predictions. You should use this data to report on the behavior of the ML recommendation system. Here, when you run the tool, remember to use the more complete production data that your team has collected, in the place of the previous limited training data. You can find the updated data here: Production Data The data-driven analysis will allow your company to ensure that the ML is working properly. However, you are also concerned with fairness. You should also include in your report a data-driven analysis of the fairness of your algorithm. To analyze the fairness, you should remember the fairness discussion we had in class, based on this tool: ML Discrimination . Then, consider two of the fairness approaches we discussed in class, and compare them. Finally, you report should include a recommendation if you want to use the ML, scrap it, or make specific improvements before rolling it out. Specifically your report should include the following information: Data-driven analysis of the predictions the model is making. Any concerns you have about the quality of the predictions in light of this data. Any features in the data you are concerned about from a fairness perspective. HINT: you might want to consult your last homework when considering this. A data-driven analysis of the interplay between these features and your ML model. There are various ways to do this, but a simple approach might consider the following: Distribution of this feature in your dataset. Distribution of this feature in your accepted and rejected recommendation populations Relationship between this feature and your false positives and false negatives. Based on this data, you should consider what is the fairness strategy that you are trying to achieve. You may use two of the fairness strategies we considered in class, or define your own. If you define a new fairness strategy, you should describe it, and present why you think it is a better fit than any of the existing strategies for this product. If you are not happy with the performance of the system, based on the data you have collected, you should do the following: Report on what aspects of the system you are unhappy with Iterate your model 1 iteration, and see if you can improve its performance. Most likely, this will NOT be enough to fix it, but your goal in this assignment is to learn enough to make a reasonable estimate of the effort needed to fix the model. Make an estimate of how long it will take to bring the model up to acceptable performance. This can be a \"T-Shirt\" estimate (e.g., S/M/L/XL) but it should also include completion criteria. This will look like specific thresholds that your model should achieve before you would be comfortable shipping it as a part of your product. At the end of this report, make a recommendation to your CTO. This recommendation should be one of the following: It is good enough to use now, we should ship it. It is not good enough to ship, but we have a plan to improve it We don't feel comfortable shipping this feature, we should scrap it.","title":"ML Model Assessment"},{"location":"assignments/HW5/#deadlines-and-deliverables","text":"This homework has one (1) deadline and two (2) deliverables. The deadline ( Friday, Nov 18 ) is for all the deliverables: the static analysis design doc, and the report on the ML model. Part A: Static Analysis - Group (due Nov 18) - 50 points (50%) The deliverable for this part is a Design Document/RFC that provides (1) a justified explanation for which tool(s) you think the project should use moving forward, and (2) how it shall be integrated into your process (you must recommend at least one tool, even if it's with reservations). This latter point should address both technical (e.g., at what point in the development/deployment process shall it be integrated? What sorts of customization or configuration will you be using?) and social issues (e.g., how will you incentivize the change?), as applicable. The justification should be based on your experiences running the tools and, as much as possible, be grounded in data about, for example, tool usability, output, and customizability. Be sure the RFC also explains/justifies the alternative tools (or process options, if pertinent) that have been rejected. To receive full credit, you must consider at least N total tool options in your RFC, where N is the size of your team. The document should also contain other relevant sections for a Design Document/RFC for this type of (development process) feature. Are there open questions? Issues you consider out of scope? Drawbacks of the proposed process/tooling that you are accepting for some (good) reason? Etc. That is: make sure it's a good/complete design document! NOTE: in your PDF submitted to gradescope, you should explictly reference at least one commit on which your tool has been run in your repo. Submit the Design Document as a single PDF to Gradescope. Part B: ML Explainability -- Group (due Nov 18) -- 50 points (50%) For this deliverable, you will be collecting data, and writing a report. The report should include the data you collect as well as your interpretation of the data. First, you should collect data by running LIME on your ML model from the last homework (use the model you have in the fall-22-hw4 repository), with the new data. You should present the results of this as data in your report. Then, you will interpret the data to explain why your machine learning model is making predictions. This information should include the features that provide the most predictive power. You should also evaluate your machine learning model considering fairness issues. You will evaluate the performance of your model with a specific target fairness strategy in mind, and if you are unhappy with the fairness of the model, you will come up with thresholds that you feel the model must meet before you would feel comfortable using it. Based on your findings, you should recommend one of three options. You might feel that the model is good enough to deploy as is, you might recommend specific changes before you deploy, or you might recommend it not be deployed at all. Submit this report as a PDF via Gradescope.","title":"Deadlines and Deliverables"},{"location":"assignments/HW6/","text":"Homework 6: Open Source Excursion In this assignment, your high-level goal is to produce and submit a non-trivial modification or extension to an open-source project in a way that maximizes the chances that the project maintainers accept it. If you demonstrate to us that your change has been accepted and integrated into the project\u2019s code base, you will get 20 bonus points . Your team will select an open source project, select a change to implement, actually contribute to the project, and present your insights to the class. You will individually reflect on your teamwork and open source experience. Part Deliverable Steps Points Due Date A Project & Task Selection 1 - 3 80 29-Nov B Project Presentations 4 - 5 100 12-Dec C Project Report 4 - 5 120 15-Dec D Individual Reflection 5 20 15-Dec Bonus If changes get accepted 4 20 15-Dec Learning Objectives Holistically apply software engineering methods in the context of a real-world problem, including process, requirements, architecture, measurement, and quality assurance. Gain broad and deep exposure to the culture and practices of open-source communities Understand commonly used infrastructure used in open-source, and how to choose infrastructure when starting a new open-source project. Engage with an open-source community. Identify process issues and suggest improvements in real-world projects, including communication, collaboration, tooling, quality assurance, formal and informal rules and policies. Coordinate within a team and adopt practices for efficient teams. Understand a project\u2019s architecture and design and make a decision about the feasibility of a proposed task. Divide and schedule work within a project. Discuss how agile practices affect development. Discuss business concerns and business models of software development. Teamwork This assignment is to be done in your assigned teams. All parts except the reflection should be done in a team context and submitted on behalf of the team. You are highly encouraged to openly discuss all issues that may arise in the process of working within the teams. Important Note : - We want to make sure that everyone is participating fully in the final project. For this project, we will be assessing participation in a variety of ways, including: artifact evaluation, self & peer evaluation (done as part of individual reflection ) - Credit due for the team will be awarded based on evidence of full participation in the team. Partial participation will receive partial credit. If severe teamwork issues arise please contact the course staff. Overview 1. Select an open source project You may select any active open source project in any language. You might find the following helpful: Trending on Github Software Quality Awards Issues that are labeled \u201cup-for-grabs\u201d goodfirstissue.dev A list of beginner friendly projects Apache projects Mozilla projects Or any project you have used before! The open source project you pick should be active, with multiple contributors. Generally you want to pick projects that are quick at reviewing & accepting PRs from external contributors for a better chance of getting your bonus. Previous students have lamented choosing dead or maintenance projects without sufficient community support. Do not make this mistake. If you have questions on if we would consider a project active, contact the course staff. 2. Select one or more bug fixes / feature extensions For the rest of this assignment, we will refer to bug fixes and feature extensions as tasks. You are free to chose the task, as long as they: are taken from a bug report or feature request in a public database or message board. Do not invent a task. Address a documented project need. make changes to the project\u2019s source code. Pure documentation or design tasks are not appropriate benefit from teamwork and are appropriate for your team size (i.e., do not select one small independent task per team member). You may choose one large task or several smaller, related tasks. The tasks should be scoped such that each team member spends one week of development effort Communicate with the project owners the task you are trying to do so that they would be more likely to accept your request in the future. If you have questions on these criteria, contact the course staff. 3. Plan the task Once you have selected a project and task(s), break them down into subtasks, consider their priority and assign them to each team member. Identify a set of tasks as your core goal for this project, and another set of tasks as stretch goals. You are expected to achieve your core goal for this project, and stretch goals as much as possible. We will work with you to adjust your goals during the check-in to ensure that they are appropriate your team size and timeframe. As per previous homeworks, plan before you start coding. You should identify risks and requirements, and develop a collaboration plan and schedule. 4. Perform the task You should perform adequate quality assurance activities when writing code. Take further steps to understand the project\u2019s code. You might find it useful to engage in intra-team discussions using static or dynamic diagrams. You might also find it useful to elicit feedback on your ideas by communicating with members of the open-source community. Submit your changes to the project Create any necessary documentation to enable acceptance of your code. Common contribution mechanisms include pull requests, emails to a project lead, or discussion board posts. You may also need to update the bug database. The project owners will review and evaluate your pull request, and you might need more work to get it approved. You are required to submit your work to the open-source project BONUS: Get your changes accepted You will get a bonus 20 (6%) bonus points upon acceptance. If your code is accepted after the homework deadline but before the final exam, inform the course staff. 5. Report, Presentation and reflection You will report on your project and task selection, work, and experience in several ways (see below). This will include a group presentation to the class. Deliverable Details Part A: Project & Tasks Selection Check-In Points : 80 Presentation Slide Deck Due Date : 29th November 2022, 11:59pm Presentation Date : 30th November 2022 / 2nd December 2022 (Recitation after Thanksgiving) The recitation after thanksigiving will be dedicated to an in-person group presentation about your project and task selection. Presentations are 6 minutes, with 3 minutes feedback and Q&A . The order of presentations will be randomly determined. Participation from all team members during the presentation is required . For full credit, you would have to be on time for the presentation session (within 5 minutes of recitation start time). If you are unable to attend in-person, you have to send a slack message to your TA with justifications 24 hours before the start of your recitation else you will receive no credit for this part of the assignment. You will then present by recording your segment of the presentation, which your teammate will play during the presentation. Guidance Pick a project following Step 1 and the open source recitation Select tasks following Step 2 Plan your tasks following Step 3 Your group presentation will serve as a check-in to determine if the open source project and task chosen was reasonable Your 6-minute check-in presentation should include (the recommended slides amount is in parenthesis): Overview and justification (~1 slide) An overview on the project you selected, summarizing the relevant characteristics you considered when making your selection. Beyond whatever additional information you collect in your research, include at least a name, a website link, and a brief description of the project (what it does, who uses it, etc). Successful build (~1 slide) Evidence that you can build and run the software (e.g., a screenshot or text output from a successful build, a screenshot of the running program). Getting an open-source project to build/run can be a huge effort, and we want to mitigate this risk. Task(s) description (~ 2-3 slides) A brief textual description of your proposed change(s). In addition to your core task(s), you may choose to include a stretch task, depending on how difficult the changes end up being, you may not need to implement it. Note that if your actual changes deviate from the plan, we expect a short explanation with the final submission. A justification why the task(s) benefit(s) from teamwork and are appropriate for your team size. Task link(s) (~ 1 slide) Evidence that the task(s) is/are requested by the community (links suffices). Subtasks & assignments (~ 1 slide) A table to summarize for each subtask description of each subtask priorities & justification of priorities of the subtasks (and if it's part of core goals or stretch goals) assignment of subtasks to team members. Risk & Mitigation Strategies (~ 1 slide) A list of at least two relevant risks when it comes to working on the tasks in your selected open source project and corresponding mitigation strategies Submit the presentation deck listed above as a single PDF file per team to Gradescope . You will be presenting this in the recitation after Thanksgiving break. Part B: Project Presentations Points : 100 Presentation Slides Due Date : 12th December 2022, 11:59pm Presentation Date : 13th / 15th December 2022, 5.30pm - 8.30pm. (During final exam timeslot) The Final Exam time is dedicated to group presentations (in-person) about your open source contributions. Presentations are 7 minutes long, with 3 minutes Q&A . The order of presentations is randomly determined. Participation from all team members during the presentation is required . Every individual will be asked to provide constructive feedback for other presentations in class via an paper form (which we will provide day-of). For full credit, you would have to be on time for the presentation session (within 10 minutes of start time). If you are unable to attend in-person, you have to send an email with justification to all instructors and cc your recitation TAs, a week before your final exam timeslot, so that appropriate arrangements can be made. Exceptions to notification deadline will only be made for unforseeable circumstances. The goal of the presentation is primarily to share with the class the project to which you contributed, and your experiences. Your presentation should cover the following topics (the recommended slides amount is in parenthesis): High-level project overview (~1 slide) Describe the project in terms of its high-level goals and the context in which it operates. This may include a brief history and the business context. E.g. it may be interesting to note that a project was spawned from a closed-source operation, or that it competes primarily with a closed-source counterpart. Brief description of the task you performed (~2 slides) Brief description of the task(s) you performed, such that the audience has sufficient context to understand your explanation of your experiences. We do not expect you to include, for example, any code or diagrams from your report , unless they\u2019re helpful for supporting a point about your interactions with the project. A demo is appreciated, but please do a screen recording instead of a live demo. Project processes and communication (~2 slides) Describe the processes and tools the project uses to coordinate among contributors. For example: Are these processes formal or informal? Provide an explicit description (possibly with a diagram) of the acceptance process used for efforts like the task you completed. If applicable, include standards or expectations regarding software engineering activities including requirements, architecture, and quality assurance; alternatively mention that no such standards exist. Your experiences (~2 slides) Summarize your experiences (and what you learned!) interacting with this community of open source developers, focusing on any surprising or unusual aspects of the process or interaction. For example: Did you run into any trouble understanding, changing, or contributing to a large, pre-existing project? Were there unanticipated challenges in either implementing your change, or in getting the change submitted to and accepted by the project maintainers? Did the project collaboration process or culture help or hinder your effort in any way? Characterize any interaction you had with the team leadership and community, highlighting especially any useful/useless input you received. You may (but are not required to) also relate the experience from this homework assignment with relevant experience from internships or other projects. Your summary of your experiences can be at whatever level of detail you think is interesting or informative. Given the time limit, selecting and highlighting the two or three most important or interesting observations is likely more useful than trying to be complete. You must upload your slides as a single PDF document to Gradescope. Part C: Project Report Points : 120 Due Date : 15 December 2022, 11:59pm After completing and submitting the modification, write a report about the tasks you have performed. Your report should include: Selected project (1 paragraph) A brief description of the open source system to which you contributed. You may reuse text from Part A. Project context and business model (<0.5 page) An analysis of the open-source project\u2019s context and business model. This may include a short history of the project, competing open- and closed-source projects, or a discussion of the developers\u2019 motivations to build this system. Essentially, we want to know why this project exists and why it is important. Task description (per task) (<0.5 page) A description of the tasks you have implemented and a high-level description of how you implemented them. Submitted artifacts (per task) Evidence of the code, documentation, or other artifacts you produced for the task, and evidence that you submitted them to the project. This would likely be links to publicly available resources (repository, email, pull request, etc). QA strategy (<1 page) Describe which QA activities you performed and justify why you selected these QA activities over others. Describe metrics if appropriate. The justification will likely refer to relevant requirements as well as to the project\u2019s practices. QA evidence Evidence of your quality assurance activities described above. For example, provide source code or links to source code of tests, provide test protocols, comments or protocols from code reviews, reports from static analysis tools, links to or screenshots from a continuous integration platform, and so forth. Plan updates (<1 page) A description and justification of deviations between your initial plans and your performed activities (as in Homework 2). Changes are expected, but they should be tracked and explained. Describe changes in scope (e.g., fewer tasks) and in the schedule and work allocation. Provide an updated schedule and note differences. Explain the causes of the changes, such as unanticipated risks. BONUS Evidence that your changes have been accepted into the code base of the open source project in forms of links or screenshots. Page limits are provided for guidance; we will not enforce them. Collect all parts in a single PDF document with clear subsections and the names of all team members and submit that file to Gradescope . Part D: Individual Reflection & Peer Evaluations Points : 20 Due Date : 15 December 2022, 11:59pm Your indiviudal reflection should include: Self Evaluation Describe the work you have done in this project (e.g. code artifacts, documentation) as well as efforts towards helping your team towards completing this project (e.g. research, organizing meetings, running meetings). Peer Evaluations Describe the specific work each of your team members have contributed towards this project. Describe both tangible (e.g. code artifacts, report & slides making, documentation) and intangible (e.g. organizing & running meetings, communicating expectations) contributions. Do point out teammates that you think are exceptional to work with in this project as well. Teamwork You have been in the same team over the course of this semester (HW 2-6). Look back on the entire semester and reflect on your team experiences. The following questions may guide you: What has worked, what hasn\u2019t? If you could start 313 or another course over with the same team, what would you change? What have you learned about teamwork and your role in teamwork? (Optional) Do you have any feedback on what we can do next year to help students work more effectively in teams? Bear in mind that the instructor-assigned heterogeneous teams of 3-5 students is non-negotiable. We anticipate problems as part of the learning experience, but would like to avoid unduly frustrating situations. A good reflection document will include concrete statements about lessons learned, with clear supporting evidence, such as examples, to support them. Submit your reflection on Gradescope .","title":"Homework 6"},{"location":"assignments/HW6/#homework-6-open-source-excursion","text":"In this assignment, your high-level goal is to produce and submit a non-trivial modification or extension to an open-source project in a way that maximizes the chances that the project maintainers accept it. If you demonstrate to us that your change has been accepted and integrated into the project\u2019s code base, you will get 20 bonus points . Your team will select an open source project, select a change to implement, actually contribute to the project, and present your insights to the class. You will individually reflect on your teamwork and open source experience. Part Deliverable Steps Points Due Date A Project & Task Selection 1 - 3 80 29-Nov B Project Presentations 4 - 5 100 12-Dec C Project Report 4 - 5 120 15-Dec D Individual Reflection 5 20 15-Dec Bonus If changes get accepted 4 20 15-Dec Learning Objectives Holistically apply software engineering methods in the context of a real-world problem, including process, requirements, architecture, measurement, and quality assurance. Gain broad and deep exposure to the culture and practices of open-source communities Understand commonly used infrastructure used in open-source, and how to choose infrastructure when starting a new open-source project. Engage with an open-source community. Identify process issues and suggest improvements in real-world projects, including communication, collaboration, tooling, quality assurance, formal and informal rules and policies. Coordinate within a team and adopt practices for efficient teams. Understand a project\u2019s architecture and design and make a decision about the feasibility of a proposed task. Divide and schedule work within a project. Discuss how agile practices affect development. Discuss business concerns and business models of software development.","title":"Homework 6: Open Source Excursion"},{"location":"assignments/HW6/#teamwork","text":"This assignment is to be done in your assigned teams. All parts except the reflection should be done in a team context and submitted on behalf of the team. You are highly encouraged to openly discuss all issues that may arise in the process of working within the teams. Important Note : - We want to make sure that everyone is participating fully in the final project. For this project, we will be assessing participation in a variety of ways, including: artifact evaluation, self & peer evaluation (done as part of individual reflection ) - Credit due for the team will be awarded based on evidence of full participation in the team. Partial participation will receive partial credit. If severe teamwork issues arise please contact the course staff.","title":"Teamwork"},{"location":"assignments/HW6/#overview","text":"","title":"Overview"},{"location":"assignments/HW6/#1-select-an-open-source-project","text":"You may select any active open source project in any language. You might find the following helpful: Trending on Github Software Quality Awards Issues that are labeled \u201cup-for-grabs\u201d goodfirstissue.dev A list of beginner friendly projects Apache projects Mozilla projects Or any project you have used before! The open source project you pick should be active, with multiple contributors. Generally you want to pick projects that are quick at reviewing & accepting PRs from external contributors for a better chance of getting your bonus. Previous students have lamented choosing dead or maintenance projects without sufficient community support. Do not make this mistake. If you have questions on if we would consider a project active, contact the course staff.","title":"1. Select an open source project"},{"location":"assignments/HW6/#2-select-one-or-more-bug-fixes-feature-extensions","text":"For the rest of this assignment, we will refer to bug fixes and feature extensions as tasks. You are free to chose the task, as long as they: are taken from a bug report or feature request in a public database or message board. Do not invent a task. Address a documented project need. make changes to the project\u2019s source code. Pure documentation or design tasks are not appropriate benefit from teamwork and are appropriate for your team size (i.e., do not select one small independent task per team member). You may choose one large task or several smaller, related tasks. The tasks should be scoped such that each team member spends one week of development effort Communicate with the project owners the task you are trying to do so that they would be more likely to accept your request in the future. If you have questions on these criteria, contact the course staff.","title":"2. Select one or more bug fixes / feature extensions"},{"location":"assignments/HW6/#3-plan-the-task","text":"Once you have selected a project and task(s), break them down into subtasks, consider their priority and assign them to each team member. Identify a set of tasks as your core goal for this project, and another set of tasks as stretch goals. You are expected to achieve your core goal for this project, and stretch goals as much as possible. We will work with you to adjust your goals during the check-in to ensure that they are appropriate your team size and timeframe. As per previous homeworks, plan before you start coding. You should identify risks and requirements, and develop a collaboration plan and schedule.","title":"3. Plan the task"},{"location":"assignments/HW6/#4-perform-the-task","text":"You should perform adequate quality assurance activities when writing code. Take further steps to understand the project\u2019s code. You might find it useful to engage in intra-team discussions using static or dynamic diagrams. You might also find it useful to elicit feedback on your ideas by communicating with members of the open-source community. Submit your changes to the project Create any necessary documentation to enable acceptance of your code. Common contribution mechanisms include pull requests, emails to a project lead, or discussion board posts. You may also need to update the bug database. The project owners will review and evaluate your pull request, and you might need more work to get it approved. You are required to submit your work to the open-source project BONUS: Get your changes accepted You will get a bonus 20 (6%) bonus points upon acceptance. If your code is accepted after the homework deadline but before the final exam, inform the course staff.","title":"4. Perform the task"},{"location":"assignments/HW6/#5-report-presentation-and-reflection","text":"You will report on your project and task selection, work, and experience in several ways (see below). This will include a group presentation to the class.","title":"5. Report, Presentation and reflection"},{"location":"assignments/HW6/#deliverable-details","text":"","title":"Deliverable Details"},{"location":"assignments/HW6/#part-a-project-tasks-selection-check-in","text":"Points : 80 Presentation Slide Deck Due Date : 29th November 2022, 11:59pm Presentation Date : 30th November 2022 / 2nd December 2022 (Recitation after Thanksgiving) The recitation after thanksigiving will be dedicated to an in-person group presentation about your project and task selection. Presentations are 6 minutes, with 3 minutes feedback and Q&A . The order of presentations will be randomly determined. Participation from all team members during the presentation is required . For full credit, you would have to be on time for the presentation session (within 5 minutes of recitation start time). If you are unable to attend in-person, you have to send a slack message to your TA with justifications 24 hours before the start of your recitation else you will receive no credit for this part of the assignment. You will then present by recording your segment of the presentation, which your teammate will play during the presentation.","title":"Part A: Project &amp; Tasks Selection Check-In"},{"location":"assignments/HW6/#guidance","text":"Pick a project following Step 1 and the open source recitation Select tasks following Step 2 Plan your tasks following Step 3 Your group presentation will serve as a check-in to determine if the open source project and task chosen was reasonable Your 6-minute check-in presentation should include (the recommended slides amount is in parenthesis): Overview and justification (~1 slide) An overview on the project you selected, summarizing the relevant characteristics you considered when making your selection. Beyond whatever additional information you collect in your research, include at least a name, a website link, and a brief description of the project (what it does, who uses it, etc). Successful build (~1 slide) Evidence that you can build and run the software (e.g., a screenshot or text output from a successful build, a screenshot of the running program). Getting an open-source project to build/run can be a huge effort, and we want to mitigate this risk. Task(s) description (~ 2-3 slides) A brief textual description of your proposed change(s). In addition to your core task(s), you may choose to include a stretch task, depending on how difficult the changes end up being, you may not need to implement it. Note that if your actual changes deviate from the plan, we expect a short explanation with the final submission. A justification why the task(s) benefit(s) from teamwork and are appropriate for your team size. Task link(s) (~ 1 slide) Evidence that the task(s) is/are requested by the community (links suffices). Subtasks & assignments (~ 1 slide) A table to summarize for each subtask description of each subtask priorities & justification of priorities of the subtasks (and if it's part of core goals or stretch goals) assignment of subtasks to team members. Risk & Mitigation Strategies (~ 1 slide) A list of at least two relevant risks when it comes to working on the tasks in your selected open source project and corresponding mitigation strategies Submit the presentation deck listed above as a single PDF file per team to Gradescope . You will be presenting this in the recitation after Thanksgiving break.","title":"Guidance"},{"location":"assignments/HW6/#part-b-project-presentations","text":"Points : 100 Presentation Slides Due Date : 12th December 2022, 11:59pm Presentation Date : 13th / 15th December 2022, 5.30pm - 8.30pm. (During final exam timeslot) The Final Exam time is dedicated to group presentations (in-person) about your open source contributions. Presentations are 7 minutes long, with 3 minutes Q&A . The order of presentations is randomly determined. Participation from all team members during the presentation is required . Every individual will be asked to provide constructive feedback for other presentations in class via an paper form (which we will provide day-of). For full credit, you would have to be on time for the presentation session (within 10 minutes of start time). If you are unable to attend in-person, you have to send an email with justification to all instructors and cc your recitation TAs, a week before your final exam timeslot, so that appropriate arrangements can be made. Exceptions to notification deadline will only be made for unforseeable circumstances. The goal of the presentation is primarily to share with the class the project to which you contributed, and your experiences. Your presentation should cover the following topics (the recommended slides amount is in parenthesis): High-level project overview (~1 slide) Describe the project in terms of its high-level goals and the context in which it operates. This may include a brief history and the business context. E.g. it may be interesting to note that a project was spawned from a closed-source operation, or that it competes primarily with a closed-source counterpart. Brief description of the task you performed (~2 slides) Brief description of the task(s) you performed, such that the audience has sufficient context to understand your explanation of your experiences. We do not expect you to include, for example, any code or diagrams from your report , unless they\u2019re helpful for supporting a point about your interactions with the project. A demo is appreciated, but please do a screen recording instead of a live demo. Project processes and communication (~2 slides) Describe the processes and tools the project uses to coordinate among contributors. For example: Are these processes formal or informal? Provide an explicit description (possibly with a diagram) of the acceptance process used for efforts like the task you completed. If applicable, include standards or expectations regarding software engineering activities including requirements, architecture, and quality assurance; alternatively mention that no such standards exist. Your experiences (~2 slides) Summarize your experiences (and what you learned!) interacting with this community of open source developers, focusing on any surprising or unusual aspects of the process or interaction. For example: Did you run into any trouble understanding, changing, or contributing to a large, pre-existing project? Were there unanticipated challenges in either implementing your change, or in getting the change submitted to and accepted by the project maintainers? Did the project collaboration process or culture help or hinder your effort in any way? Characterize any interaction you had with the team leadership and community, highlighting especially any useful/useless input you received. You may (but are not required to) also relate the experience from this homework assignment with relevant experience from internships or other projects. Your summary of your experiences can be at whatever level of detail you think is interesting or informative. Given the time limit, selecting and highlighting the two or three most important or interesting observations is likely more useful than trying to be complete. You must upload your slides as a single PDF document to Gradescope.","title":"Part B: Project Presentations"},{"location":"assignments/HW6/#part-c-project-report","text":"Points : 120 Due Date : 15 December 2022, 11:59pm After completing and submitting the modification, write a report about the tasks you have performed. Your report should include: Selected project (1 paragraph) A brief description of the open source system to which you contributed. You may reuse text from Part A. Project context and business model (<0.5 page) An analysis of the open-source project\u2019s context and business model. This may include a short history of the project, competing open- and closed-source projects, or a discussion of the developers\u2019 motivations to build this system. Essentially, we want to know why this project exists and why it is important. Task description (per task) (<0.5 page) A description of the tasks you have implemented and a high-level description of how you implemented them. Submitted artifacts (per task) Evidence of the code, documentation, or other artifacts you produced for the task, and evidence that you submitted them to the project. This would likely be links to publicly available resources (repository, email, pull request, etc). QA strategy (<1 page) Describe which QA activities you performed and justify why you selected these QA activities over others. Describe metrics if appropriate. The justification will likely refer to relevant requirements as well as to the project\u2019s practices. QA evidence Evidence of your quality assurance activities described above. For example, provide source code or links to source code of tests, provide test protocols, comments or protocols from code reviews, reports from static analysis tools, links to or screenshots from a continuous integration platform, and so forth. Plan updates (<1 page) A description and justification of deviations between your initial plans and your performed activities (as in Homework 2). Changes are expected, but they should be tracked and explained. Describe changes in scope (e.g., fewer tasks) and in the schedule and work allocation. Provide an updated schedule and note differences. Explain the causes of the changes, such as unanticipated risks. BONUS Evidence that your changes have been accepted into the code base of the open source project in forms of links or screenshots. Page limits are provided for guidance; we will not enforce them. Collect all parts in a single PDF document with clear subsections and the names of all team members and submit that file to Gradescope .","title":"Part C: Project Report"},{"location":"assignments/HW6/#part-d-individual-reflection-peer-evaluations","text":"Points : 20 Due Date : 15 December 2022, 11:59pm Your indiviudal reflection should include: Self Evaluation Describe the work you have done in this project (e.g. code artifacts, documentation) as well as efforts towards helping your team towards completing this project (e.g. research, organizing meetings, running meetings). Peer Evaluations Describe the specific work each of your team members have contributed towards this project. Describe both tangible (e.g. code artifacts, report & slides making, documentation) and intangible (e.g. organizing & running meetings, communicating expectations) contributions. Do point out teammates that you think are exceptional to work with in this project as well. Teamwork You have been in the same team over the course of this semester (HW 2-6). Look back on the entire semester and reflect on your team experiences. The following questions may guide you: What has worked, what hasn\u2019t? If you could start 313 or another course over with the same team, what would you change? What have you learned about teamwork and your role in teamwork? (Optional) Do you have any feedback on what we can do next year to help students work more effectively in teams? Bear in mind that the instructor-assigned heterogeneous teams of 3-5 students is non-negotiable. We anticipate problems as part of the learning experience, but would like to avoid unduly frustrating situations. A good reflection document will include concrete statements about lessons learned, with clear supporting evidence, such as examples, to support them. Submit your reflection on Gradescope .","title":"Part D: Individual Reflection &amp; Peer Evaluations"},{"location":"recitations/reci2-angularjs/","text":"Recitation 2: Crash Course in Angular.js Overview This recitation aims to highlight the basics of Angular.js by walking students through the implementation of a basic To-Do list app. Students will be expected to use this knowledge to make changes to the Angular.js components of the Teedy project in a future assignment. Pre-requisites Basic understanding of how the web works Basic HTML/CSS knowledge Basic JavaScript knowledge Task 0: Fork the repl Create an account on repl.it Fork this repl - you\u2019ll be using this to work through this exercise and see your changes When you run the app you should see something like the below screenshot. At this point, all the static HTML for the todo list has been set up. You\u2019ll be working on making the todo list app function properly using Angular.js Task 1: Setup Angular.js Goal: Convert the basic HTML skeleton in the repl to an Angular.js app Steps: Import the Angular.js library by adding the following script tag to the head component of index.html <script src=\"https://ajax.googleapis.com/ajax/libs/angularjs/1.8.2/angular.min.js\"></script> Add the ng-app directive to the main <html> tag to specify the root of your app This involves changing the <html> tag at the top of index.html to <html ng-app> Task 2: Data Binding Basics Goal: Display a dynamic title based on user input Steps: Use the ng-model directive to tie the value in the name text input field to a variable in the Angular.js app\u2019s model. Add ng-model=\"varName\" to the name text input tag Include {{varName}} in the Hello here's your todo list string to bind the data in the model to the title in the view Changing the value in the name text field should now change the title in real-time Task 3: Setting up the controller Goal: A boiler-plate controller called TodoListController has been set up in app.js. We want to connect our app with this controller so we can get more control over our todo list Steps: Import app.js by adding the following script tag to the head component of index.html <script src=\"app.js\"></script> Change the ng-app directive to bind to todoApp Change <html ng-app> at the top of index.html to <html ng-app=\"todoApp\"> Add the ng-controller directive to bind the TodoListController Change the opening <body> tag to <body ng-controller=\"TodoListController as todoList\"> Now we can access the controller within the body tag using the todoList alias Task 4: Rendering the list of todo items Goal: There\u2019s a list called todos in our controller that we\u2019ll use to store our todo list items. We want to replace the static todo list item with the todo items in this list Steps: Use the ng-repeat directive to render items in the list Change the <li> tag that renders a list item to <li ng-repeat=\"todo in todoList.todos\"> Add the ng-model=\"todo.done\" directive to the checkbox input tag so the checkbox reflects the value in the done field of a given todo list item Replace the static todo list item text with {{todo.text}} to render the text associated with a given todo item in the list Changing the data in the todos list in app.js should now change the contents of the todo list rendered Task 5: Adding new todo items Goal: Allow users to add new todos to the list using the form in the app Steps: Use the ng-model directive to tie the value in the new todo text input field to a variable in the angular.js app\u2019s model Add ng-model=\"todoList.todoText\" to the add new todo here text input tag Implement the todoList.addTodo function in app.js Add a new todo item to the list using the data in todoList.todoText Clear the text input field by setting todoList.todoText to the empty string Add the ng-submit directive to the form to call this addTodo function on submit by changing the opening <form> tag to <form ng-submit=\"todoList.addTodo()\"> Task 6: Special styling for completed todo items Goal: We want to apply custom styling for completed todo items, so they appear crossed out Steps: A CSS class called done-true for completed todo items has been implemented in style.css . Make any changes you\u2019d like to this CSS class Apply this class to the todo text item Change the <span> tag used to render {{todo.text}} to <span class=\"done-{{todo.done}}\"> Checking a given todo item should lead to the custom css class being applied to that item","title":"Recitation 2"},{"location":"recitations/reci2-angularjs/#recitation-2-crash-course-in-angularjs","text":"","title":"Recitation 2: Crash Course in Angular.js"},{"location":"recitations/reci2-angularjs/#overview","text":"This recitation aims to highlight the basics of Angular.js by walking students through the implementation of a basic To-Do list app. Students will be expected to use this knowledge to make changes to the Angular.js components of the Teedy project in a future assignment.","title":"Overview"},{"location":"recitations/reci2-angularjs/#pre-requisites","text":"Basic understanding of how the web works Basic HTML/CSS knowledge Basic JavaScript knowledge","title":"Pre-requisites"},{"location":"recitations/reci2-angularjs/#task-0-fork-the-repl","text":"Create an account on repl.it Fork this repl - you\u2019ll be using this to work through this exercise and see your changes When you run the app you should see something like the below screenshot. At this point, all the static HTML for the todo list has been set up. You\u2019ll be working on making the todo list app function properly using Angular.js","title":"Task 0: Fork the repl"},{"location":"recitations/reci2-angularjs/#task-1-setup-angularjs","text":"Goal: Convert the basic HTML skeleton in the repl to an Angular.js app Steps: Import the Angular.js library by adding the following script tag to the head component of index.html <script src=\"https://ajax.googleapis.com/ajax/libs/angularjs/1.8.2/angular.min.js\"></script> Add the ng-app directive to the main <html> tag to specify the root of your app This involves changing the <html> tag at the top of index.html to <html ng-app>","title":"Task 1: Setup Angular.js"},{"location":"recitations/reci2-angularjs/#task-2-data-binding-basics","text":"Goal: Display a dynamic title based on user input Steps: Use the ng-model directive to tie the value in the name text input field to a variable in the Angular.js app\u2019s model. Add ng-model=\"varName\" to the name text input tag Include {{varName}} in the Hello here's your todo list string to bind the data in the model to the title in the view Changing the value in the name text field should now change the title in real-time","title":"Task 2: Data Binding Basics"},{"location":"recitations/reci2-angularjs/#task-3-setting-up-the-controller","text":"Goal: A boiler-plate controller called TodoListController has been set up in app.js. We want to connect our app with this controller so we can get more control over our todo list Steps: Import app.js by adding the following script tag to the head component of index.html <script src=\"app.js\"></script> Change the ng-app directive to bind to todoApp Change <html ng-app> at the top of index.html to <html ng-app=\"todoApp\"> Add the ng-controller directive to bind the TodoListController Change the opening <body> tag to <body ng-controller=\"TodoListController as todoList\"> Now we can access the controller within the body tag using the todoList alias","title":"Task 3: Setting up the controller"},{"location":"recitations/reci2-angularjs/#task-4-rendering-the-list-of-todo-items","text":"Goal: There\u2019s a list called todos in our controller that we\u2019ll use to store our todo list items. We want to replace the static todo list item with the todo items in this list Steps: Use the ng-repeat directive to render items in the list Change the <li> tag that renders a list item to <li ng-repeat=\"todo in todoList.todos\"> Add the ng-model=\"todo.done\" directive to the checkbox input tag so the checkbox reflects the value in the done field of a given todo list item Replace the static todo list item text with {{todo.text}} to render the text associated with a given todo item in the list Changing the data in the todos list in app.js should now change the contents of the todo list rendered","title":"Task 4: Rendering the list of todo items"},{"location":"recitations/reci2-angularjs/#task-5-adding-new-todo-items","text":"Goal: Allow users to add new todos to the list using the form in the app Steps: Use the ng-model directive to tie the value in the new todo text input field to a variable in the angular.js app\u2019s model Add ng-model=\"todoList.todoText\" to the add new todo here text input tag Implement the todoList.addTodo function in app.js Add a new todo item to the list using the data in todoList.todoText Clear the text input field by setting todoList.todoText to the empty string Add the ng-submit directive to the form to call this addTodo function on submit by changing the opening <form> tag to <form ng-submit=\"todoList.addTodo()\">","title":"Task 5: Adding new todo items"},{"location":"recitations/reci2-angularjs/#task-6-special-styling-for-completed-todo-items","text":"Goal: We want to apply custom styling for completed todo items, so they appear crossed out Steps: A CSS class called done-true for completed todo items has been implemented in style.css . Make any changes you\u2019d like to this CSS class Apply this class to the todo text item Change the <span> tag used to render {{todo.text}} to <span class=\"done-{{todo.done}}\"> Checking a given todo item should lead to the custom css class being applied to that item","title":"Task 6: Special styling for completed todo items"},{"location":"recitations/reci3-archaeology/","text":"Recitation 3: Software Archaeology Overview In today\u2019s recitation, we will practice getting to know an unknown codebase specifically in the context of fixing bugs in an open-source software system. We will do this by exploring bugs in OpenRefine, a Java tool for loading, cleaning, and augmenting data. Pre-requisites You may optionally wish to peruse these docs to introduce yourself to how to use OpenRefine. Let's fix some bugs! Consider the following open bug: https://github.com/OpenRefine/OpenRefine/issues/5034 Task 0: Clone the repo Clone the repository at https://github.com/OpenRefine/OpenRefine Run with ./refine in the project directory Task 1: Reproduce the bug Look at the issue above and reproduce it manually as in the description Task 2: Diving into the code Let\u2019s learn more about this bug! Your high level goal is to identify the code that is implicated in the bug and learn more about the bug en route to fixing it. Note that we don\u2019t expect you to actually fix it, it\u2019s open for a reason, but we\u2019d like you to learn about the code being executed and learn a little bit about what\u2019s going on. (It\u2019s okay if you don\u2019t get to all of these tasks.) Try some or all of the following tasks: Explore the tests directory Can you find a test that looks like it might test the same code you\u2019ve been exploring in these bugs? (hint: the bug involves importing an Excel file) Use your IDE to jump to a definition implicated in the code you\u2019re debugging Find similar code to the code that\u2019s involved in the error (hint: the code adds a column called File, and one of the cells involves the file source) Try making a change! It will reflect in the UI. Can you fix the bug? If you\u2019ve finished all that, practice playing around with testing with Maven : - Write a test that fails due to the bug - Change the code so that that your new test pass - Change the code so that a different error is thrown - Change your tests such that an error isn\u2019t thrown","title":"Recitation 3"},{"location":"recitations/reci3-archaeology/#recitation-3-software-archaeology","text":"","title":"Recitation 3: Software Archaeology"},{"location":"recitations/reci3-archaeology/#overview","text":"In today\u2019s recitation, we will practice getting to know an unknown codebase specifically in the context of fixing bugs in an open-source software system. We will do this by exploring bugs in OpenRefine, a Java tool for loading, cleaning, and augmenting data.","title":"Overview"},{"location":"recitations/reci3-archaeology/#pre-requisites","text":"You may optionally wish to peruse these docs to introduce yourself to how to use OpenRefine. Let's fix some bugs! Consider the following open bug: https://github.com/OpenRefine/OpenRefine/issues/5034","title":"Pre-requisites"},{"location":"recitations/reci3-archaeology/#task-0-clone-the-repo","text":"Clone the repository at https://github.com/OpenRefine/OpenRefine Run with ./refine in the project directory","title":"Task 0: Clone the repo"},{"location":"recitations/reci3-archaeology/#task-1-reproduce-the-bug","text":"Look at the issue above and reproduce it manually as in the description","title":"Task 1: Reproduce the bug"},{"location":"recitations/reci3-archaeology/#task-2-diving-into-the-code","text":"Let\u2019s learn more about this bug! Your high level goal is to identify the code that is implicated in the bug and learn more about the bug en route to fixing it. Note that we don\u2019t expect you to actually fix it, it\u2019s open for a reason, but we\u2019d like you to learn about the code being executed and learn a little bit about what\u2019s going on. (It\u2019s okay if you don\u2019t get to all of these tasks.) Try some or all of the following tasks: Explore the tests directory Can you find a test that looks like it might test the same code you\u2019ve been exploring in these bugs? (hint: the bug involves importing an Excel file) Use your IDE to jump to a definition implicated in the code you\u2019re debugging Find similar code to the code that\u2019s involved in the error (hint: the code adds a column called File, and one of the cells involves the file source) Try making a change! It will reflect in the UI. Can you fix the bug? If you\u2019ve finished all that, practice playing around with testing with Maven : - Write a test that fails due to the bug - Change the code so that that your new test pass - Change the code so that a different error is thrown - Change your tests such that an error isn\u2019t thrown","title":"Task 2: Diving into the code"},{"location":"recitations/reci4-dysfunction/","text":"Recitation 4: Team Dysfunction Overview This recitation will give you the opportunity to practice and reflect on the roles you play within a team. We'll be going over common team dysfunction issues and discuss mitigation strategies. Context All teams are inherently dysfunctional in some sense. This is inevitable as they are made up of fallible, imperfect human beings, each with different goals and intentions. Thankfully, the causes of dysfunction are both identifiable and curable, but definitely not easy to resolve. Making a team functional and cohesive requires courage, good communication, and a strong resolve to making the team better. Part 0: Preparation Use a random number generator to get a random number from 1-7. Next, check Appendix A for a detailed description of the role associated with your generated number. Keep your role secret from the other people in your group! Part 1: Trade-off and Task Planning Meeting (15 min) Congratulations! Your team has been hired as software developers to work on CMU's graduate school application system. For your first assignment, you've been asked to develop a better system for handling online payments made by graduate students for their applications. Task: As a team, research and find tools that can be used to improve the payment system. This can be anything from supporting better payment methods, storing payment information, etc. Compare the strengths and weaknesses of the tools. At the end of this activity, your group should have agreed on a tool to use. Be sure to also assign each member a task in order to integrate the tool into the payment system. Activity Notes: Each team member should keep their role secret and try to act accordingly during the meeting. Try to identify the roles played by your team members and, if possible, fix the dysfunction. Part 2: Group Discussion (10 min) As a group, discuss the following questions: 1. What dysfunctional characteristic did your teammates display? 2. How would you handle those dysfunctional characteristics in future situations? Then, as a group, prepare some responses to the questions in Part 3 . Part 3: Class Discussion (10 min) As a class, discuss the following questions: 1. Was the meeting effective? Why or why not? 2. What team dysfunctions did you observe during the meeting? 3. Were there any instances where your role directly clashed with someone else in your group? 4. Were you able to identify the roles played by the other members? What problems were caused by their behavior? 5. Can you think of mitigation strategies and solutions to avoid these problems? Appendix A: Role Descriptions Below a description of the roles for each number 1-7 and the behavior of each one: 1. The Contributor: You are aiming for general team success. Ask for your team members' opinions often, actively discuss solutions with your team, and demonstrate engagement throughout the activity. 2. The Know-It-All: You think you are extremely experienced and know how to solve all problems on your own. Act like you don't need any help and just tell your team to watch while you search for the tool. Be pushy in telling other members how to search for information about the tool and shoot other members' ideas down. 3. The Silent One: You assume your team members know everything and don\u2019t feel you need to say much. Pay attention to the meeting, but simply do not suggest anything. Remain passive but friendly. 4. The Agreer: You are afraid of raising conflicts and hence decided to just go along with whatever your team decides. Agree with everything during the activity and do not question the decisions of your team. 5. The Hitchhiker: Your goal is to do as little work as possible. Be friendly but not productive. Try to end the meeting as quickly as possible so you can slack off. Get other people to step in for you and take over your tasks. Make fake attempts to make it look like you tried to figure out the task, then pass off the work to someone else. 6. The Flaker: You're interested in the project, but don't want to contribute more time than necessary. Actively contribute to group discussions until tasks are being assigned, then begin giving reasons why you can't contribute more (i.e. busy with interview prep, midterm, or other assignments). If asked to do something else, continue finding other excuses on why you can\u2019t contribute. 7. The Perfectionist: You want this project to be absolutely perfect in even the most minor details. To you, it's most important that the tool\u2019s source code is fully readable, perfectly documented, has a large test suite, and is aesthetically pleasing , and you will argue for or against the tool based on these minor details.","title":"Recitation 4"},{"location":"recitations/reci4-dysfunction/#recitation-4-team-dysfunction","text":"","title":"Recitation 4: Team Dysfunction"},{"location":"recitations/reci4-dysfunction/#overview","text":"This recitation will give you the opportunity to practice and reflect on the roles you play within a team. We'll be going over common team dysfunction issues and discuss mitigation strategies.","title":"Overview"},{"location":"recitations/reci4-dysfunction/#context","text":"All teams are inherently dysfunctional in some sense. This is inevitable as they are made up of fallible, imperfect human beings, each with different goals and intentions. Thankfully, the causes of dysfunction are both identifiable and curable, but definitely not easy to resolve. Making a team functional and cohesive requires courage, good communication, and a strong resolve to making the team better.","title":"Context"},{"location":"recitations/reci4-dysfunction/#part-0-preparation","text":"Use a random number generator to get a random number from 1-7. Next, check Appendix A for a detailed description of the role associated with your generated number. Keep your role secret from the other people in your group!","title":"Part 0: Preparation"},{"location":"recitations/reci4-dysfunction/#part-1-trade-off-and-task-planning-meeting-15-min","text":"Congratulations! Your team has been hired as software developers to work on CMU's graduate school application system. For your first assignment, you've been asked to develop a better system for handling online payments made by graduate students for their applications. Task: As a team, research and find tools that can be used to improve the payment system. This can be anything from supporting better payment methods, storing payment information, etc. Compare the strengths and weaknesses of the tools. At the end of this activity, your group should have agreed on a tool to use. Be sure to also assign each member a task in order to integrate the tool into the payment system. Activity Notes: Each team member should keep their role secret and try to act accordingly during the meeting. Try to identify the roles played by your team members and, if possible, fix the dysfunction.","title":"Part 1: Trade-off and Task Planning Meeting (15 min)"},{"location":"recitations/reci4-dysfunction/#part-2-group-discussion-10-min","text":"As a group, discuss the following questions: 1. What dysfunctional characteristic did your teammates display? 2. How would you handle those dysfunctional characteristics in future situations? Then, as a group, prepare some responses to the questions in Part 3 .","title":"Part 2: Group Discussion (10 min)"},{"location":"recitations/reci4-dysfunction/#part-3-class-discussion-10-min","text":"As a class, discuss the following questions: 1. Was the meeting effective? Why or why not? 2. What team dysfunctions did you observe during the meeting? 3. Were there any instances where your role directly clashed with someone else in your group? 4. Were you able to identify the roles played by the other members? What problems were caused by their behavior? 5. Can you think of mitigation strategies and solutions to avoid these problems?","title":"Part 3: Class Discussion (10 min)"},{"location":"recitations/reci4-dysfunction/#appendix-a-role-descriptions","text":"Below a description of the roles for each number 1-7 and the behavior of each one: 1. The Contributor: You are aiming for general team success. Ask for your team members' opinions often, actively discuss solutions with your team, and demonstrate engagement throughout the activity. 2. The Know-It-All: You think you are extremely experienced and know how to solve all problems on your own. Act like you don't need any help and just tell your team to watch while you search for the tool. Be pushy in telling other members how to search for information about the tool and shoot other members' ideas down. 3. The Silent One: You assume your team members know everything and don\u2019t feel you need to say much. Pay attention to the meeting, but simply do not suggest anything. Remain passive but friendly. 4. The Agreer: You are afraid of raising conflicts and hence decided to just go along with whatever your team decides. Agree with everything during the activity and do not question the decisions of your team. 5. The Hitchhiker: Your goal is to do as little work as possible. Be friendly but not productive. Try to end the meeting as quickly as possible so you can slack off. Get other people to step in for you and take over your tasks. Make fake attempts to make it look like you tried to figure out the task, then pass off the work to someone else. 6. The Flaker: You're interested in the project, but don't want to contribute more time than necessary. Actively contribute to group discussions until tasks are being assigned, then begin giving reasons why you can't contribute more (i.e. busy with interview prep, midterm, or other assignments). If asked to do something else, continue finding other excuses on why you can\u2019t contribute. 7. The Perfectionist: You want this project to be absolutely perfect in even the most minor details. To you, it's most important that the tool\u2019s source code is fully readable, perfectly documented, has a large test suite, and is aesthetically pleasing , and you will argue for or against the tool based on these minor details.","title":"Appendix A: Role Descriptions"},{"location":"recitations/reci6-midterm-review/","text":"Recitation 6: Midterm Review Overview As we have our midterm scheduled for Tuesday, October 11th, this recitation slot will be used for a midterm review. Complete the exams from past years listed below and come to recitation with any questions! Note: As we have not yet covered software engineering for ML this semester, please ignore those questions. The SE4ML material will not appear on the exam. Exams Fall 2019 Fall 2020 Fall 2021","title":"Recitation 6"},{"location":"recitations/reci6-midterm-review/#recitation-6-midterm-review","text":"","title":"Recitation 6: Midterm Review"},{"location":"recitations/reci6-midterm-review/#overview","text":"As we have our midterm scheduled for Tuesday, October 11th, this recitation slot will be used for a midterm review. Complete the exams from past years listed below and come to recitation with any questions! Note: As we have not yet covered software engineering for ML this semester, please ignore those questions. The SE4ML material will not appear on the exam.","title":"Overview"},{"location":"recitations/reci6-midterm-review/#exams","text":"Fall 2019 Fall 2020 Fall 2021","title":"Exams"},{"location":"recitations/reci7-machine-learning/","text":"Recitation 7: Machine Learning Setup Instructions (10 min): Go to this GitHub repo - Click the code button, switch to codespaces, and click green create codespace on main button Overview During this recitation, students will have the opportunity to play with various machine learning frameworks and tools (e.g., such as pandas, LIME, and Jupyter Notebooks.) Students will work with a partner. Context We can use the Titanic dataset to make predictions on whether or not passengers would survive given features in the dataset. We saw how gender was one feature that predicted if a passenger would survive, but during class several other ideas were proposed as well. For example, one might consider if fare paid was a good proxy for predicting if a passenger would survive. Activity 1: Examine the Titanic dataset (10 mins) This dataset contains detailed information on the passengers aboard the Titanic. Our goal is to create a model able to predict whether a passenger will survive. However, before we start training our machine learning model, let us first explore the dataset. Use the pandas methods we went over earlier and explore what features are in the dataset. Then choose one feature and explore its correlation with passenger survival rate. Hypothesize an explanation for why it has such effects. Activity 2: Train your model (20 min) Using what we have learned earlier about decision trees and random forest classifiers, work with your partner to train your own model to predict whether a passenger with given features will survive. Be sure to calculate the accuracy of your model using the given test dataset. Activity 3: Present your findings to the class (10 min) Each partner pair should share how you trained your model (e.g. what features you considered) and what accuracy level you were able to obtain on the test set","title":"Recitation 7"},{"location":"recitations/reci7-machine-learning/#recitation-7-machine-learning","text":"","title":"Recitation 7:  Machine Learning"},{"location":"recitations/reci7-machine-learning/#setup-instructions-10-min","text":"Go to this GitHub repo - Click the code button, switch to codespaces, and click green create codespace on main button","title":"Setup Instructions (10 min):"},{"location":"recitations/reci7-machine-learning/#overview","text":"During this recitation, students will have the opportunity to play with various machine learning frameworks and tools (e.g., such as pandas, LIME, and Jupyter Notebooks.) Students will work with a partner.","title":"Overview"},{"location":"recitations/reci7-machine-learning/#context","text":"We can use the Titanic dataset to make predictions on whether or not passengers would survive given features in the dataset. We saw how gender was one feature that predicted if a passenger would survive, but during class several other ideas were proposed as well. For example, one might consider if fare paid was a good proxy for predicting if a passenger would survive.","title":"Context"},{"location":"recitations/reci7-machine-learning/#activity-1-examine-the-titanic-dataset-10-mins","text":"This dataset contains detailed information on the passengers aboard the Titanic. Our goal is to create a model able to predict whether a passenger will survive. However, before we start training our machine learning model, let us first explore the dataset. Use the pandas methods we went over earlier and explore what features are in the dataset. Then choose one feature and explore its correlation with passenger survival rate. Hypothesize an explanation for why it has such effects.","title":"Activity 1: Examine the Titanic dataset (10 mins)"},{"location":"recitations/reci7-machine-learning/#activity-2-train-your-model-20-min","text":"Using what we have learned earlier about decision trees and random forest classifiers, work with your partner to train your own model to predict whether a passenger with given features will survive. Be sure to calculate the accuracy of your model using the given test dataset.","title":"Activity 2: Train your model (20 min)"},{"location":"recitations/reci7-machine-learning/#activity-3-present-your-findings-to-the-class-10-min","text":"Each partner pair should share how you trained your model (e.g. what features you considered) and what accuracy level you were able to obtain on the test set","title":"Activity 3: Present your findings to the class (10 min)"},{"location":"recitations/reci8-static-analysis-ci/","text":"Recitation 8: static analysis and continuous integration Static and dynamic analysis tools help you keep the codebase healthy. In this recitation, we will learn how to set up these tools in CI (GitHub Actions). Step 1: Setup your sample Python repo First, go to this template repo and use it to create your own repo. The repo is very similar to the HW4 repo, except that it comes with a failing test. You already learned that it's a big no-no to push directly to main . We can actually enforce this using branch protect rules . Read the docs to understand what they are, and set the following rules: Requires a pull request before merging to main Requires tests to pass before merging to main : Search for the job name in the required checks (i.e. test in this case.) You may need to save the settings first before this search box appears. Your setting should look like this: The failing test cases \u274c wouldn\u2019t have been there if I had these rules enabled in the first place. Now, let's fix our failing test. Step 2: Fix the broken CI The \u274c really shouldn't have been there in the first place if I had these rules enabled. Now let's fix it. Branch off from main and create a PR to fix the broken CI. Take a look in the Actions page to see which test is failing. Branch off from main and create a PR to fix the broken CI. (the fix should be VERY simple!) The test job should pass on your PR. Click \"Squash and merge\"* to merge after the status checks pass. *: It's just a lot cleaner than the default merge. HINT: If you are really stuck on how to fix, click here Step 3: Make your code pretty Different tab sizes driving you crazy? Let's use a tool to standardize them all. A code formatter, a static analysis tool, helps one identify and fix formatting issues in the codebase. Let's use black as an example. First, create another branch for setting up a code formatter. Then, run the following commands to install it locally and try running it: pipenv install --dev black : black is only a development dependency . Your package doesn't actually use it. pipenv run black . --check : Runs black in the current directory. --check dry-runs black and don't alter any files. Observe some files on the list. pipenv run black . : This will actually change the files. Run git diff to observe the file changes. Using CI, we can enforce formatting requirements using the same GH Actions + status checks. For popular tools, someone has done it before, and you can reuse their workflow. Go to this existing black Actions on GH Marketplace Click \"Use lastest version\" to see what needs to be added to .github/workflows/main.yml Add another job called \u201cformat\u201d to the main.yml file to use black to check the file formatting Push your formatted files to the branch and observe format passes. Squash and merge the PR Step 4: Add test coverage to the CI workflow Finally, you can also do some dynamic analysis. Since we are already using pytest , let's use pytest-cov , a plugin that reports test coverage. First, install and try to use it locally: Create another branch Install pytest-cov locally: pipenv install --dev pytest-cov Runs pytest with coverage report: pipenv run pytest --cov=app Now, let's add another job in the workflow for reporting coverage: From the test workflow, copy the steps before pytest Now, run pipenv run pytest --cov=app to report coverage Push and observe the new check running Bonus: report coverage in PRs The coverage job doesn't really add much to the workflow now since it doesn't fail. Without being too strict about coverage, we can at least display the coverage status in the PR. Somebody has already done it , so we can use it in our repo too. Hint : you should only need the last two steps in the workflow. Note that this action will only run on pull request-based workflows, so you will need to modify your triggers. If set up, the job will automatically comment on PRs with the coverage info:","title":"Recitation 8"},{"location":"recitations/reci8-static-analysis-ci/#recitation-8-static-analysis-and-continuous-integration","text":"Static and dynamic analysis tools help you keep the codebase healthy. In this recitation, we will learn how to set up these tools in CI (GitHub Actions).","title":"Recitation 8: static analysis and continuous integration"},{"location":"recitations/reci8-static-analysis-ci/#step-1-setup-your-sample-python-repo","text":"First, go to this template repo and use it to create your own repo. The repo is very similar to the HW4 repo, except that it comes with a failing test. You already learned that it's a big no-no to push directly to main . We can actually enforce this using branch protect rules . Read the docs to understand what they are, and set the following rules: Requires a pull request before merging to main Requires tests to pass before merging to main : Search for the job name in the required checks (i.e. test in this case.) You may need to save the settings first before this search box appears. Your setting should look like this: The failing test cases \u274c wouldn\u2019t have been there if I had these rules enabled in the first place. Now, let's fix our failing test.","title":"Step 1: Setup your sample Python repo"},{"location":"recitations/reci8-static-analysis-ci/#step-2-fix-the-broken-ci","text":"The \u274c really shouldn't have been there in the first place if I had these rules enabled. Now let's fix it. Branch off from main and create a PR to fix the broken CI. Take a look in the Actions page to see which test is failing. Branch off from main and create a PR to fix the broken CI. (the fix should be VERY simple!) The test job should pass on your PR. Click \"Squash and merge\"* to merge after the status checks pass. *: It's just a lot cleaner than the default merge. HINT: If you are really stuck on how to fix, click here","title":"Step 2: Fix the broken CI"},{"location":"recitations/reci8-static-analysis-ci/#step-3-make-your-code-pretty","text":"Different tab sizes driving you crazy? Let's use a tool to standardize them all. A code formatter, a static analysis tool, helps one identify and fix formatting issues in the codebase. Let's use black as an example. First, create another branch for setting up a code formatter. Then, run the following commands to install it locally and try running it: pipenv install --dev black : black is only a development dependency . Your package doesn't actually use it. pipenv run black . --check : Runs black in the current directory. --check dry-runs black and don't alter any files. Observe some files on the list. pipenv run black . : This will actually change the files. Run git diff to observe the file changes. Using CI, we can enforce formatting requirements using the same GH Actions + status checks. For popular tools, someone has done it before, and you can reuse their workflow. Go to this existing black Actions on GH Marketplace Click \"Use lastest version\" to see what needs to be added to .github/workflows/main.yml Add another job called \u201cformat\u201d to the main.yml file to use black to check the file formatting Push your formatted files to the branch and observe format passes. Squash and merge the PR","title":"Step 3: Make your code pretty"},{"location":"recitations/reci8-static-analysis-ci/#step-4-add-test-coverage-to-the-ci-workflow","text":"Finally, you can also do some dynamic analysis. Since we are already using pytest , let's use pytest-cov , a plugin that reports test coverage. First, install and try to use it locally: Create another branch Install pytest-cov locally: pipenv install --dev pytest-cov Runs pytest with coverage report: pipenv run pytest --cov=app Now, let's add another job in the workflow for reporting coverage: From the test workflow, copy the steps before pytest Now, run pipenv run pytest --cov=app to report coverage Push and observe the new check running","title":"Step 4: Add test coverage to the CI workflow"},{"location":"recitations/reci8-static-analysis-ci/#bonus-report-coverage-in-prs","text":"The coverage job doesn't really add much to the workflow now since it doesn't fail. Without being too strict about coverage, we can at least display the coverage status in the PR. Somebody has already done it , so we can use it in our repo too. Hint : you should only need the last two steps in the workflow. Note that this action will only run on pull request-based workflows, so you will need to modify your triggers. If set up, the job will automatically comment on PRs with the coverage info:","title":"Bonus: report coverage in PRs"},{"location":"recitations/reci9-open-source/","text":"Recitation 9: Open Source Projects Overview This recitation will give you the opportunity to familiarize yourself with various open source projects and help your team with finding a project to work on for Homework 6. Context Open source software refers to software where the code is openly available, allowing contributors to freely run, modify, contribute, and redistribute the code. These projects provide a great learning experience of working with large codebases to beginner programmers, and give you the opportunity to contribute to software that\u2019s used by a large number of community members. The general criteria for an open source project: - Repository must be public & open to outside contributors - Repository must have an open source license Scavenger Hunt (30 min) Join the slide deck made by your TA for your class and make a copy of the slide for your team. Then, search for open source projects to fill each square in the Scavenger Hunt table. Each project can only count for one square. The goal is to have as many squares filled as possible! Squares marked with ** can only be claimed by one team in the room - you must fulfill what\u2019s described in the square to claim it. Reflection (10 min) With your team, discuss the following questions: - Which attributes make a good open source project? A bad open source project? - Which projects did you find that you would most like to work on? Which would you least like to work on? Why? Resources A list of beginner friendly projects: https://github.com/MunGell/awesome-for-beginners Github Showcase for new contributors: https://github.com/showcases/great-for-new-contributors Issues that are labeled \u201cup-for-grabs\u201d: https://up-for-grabs.net Apache projects: http://www.apache.org/ Mozilla projects: https://developer.mozilla.org/en-US/docs/MDN/Community/Contributing Mozilla has a number of Open Source projects (including Firefox and Thunderbird) that are actively being developed and they recommend bugs for new contributors","title":"Recitation 9"},{"location":"recitations/reci9-open-source/#recitation-9-open-source-projects","text":"","title":"Recitation 9: Open Source Projects"},{"location":"recitations/reci9-open-source/#overview","text":"This recitation will give you the opportunity to familiarize yourself with various open source projects and help your team with finding a project to work on for Homework 6.","title":"Overview"},{"location":"recitations/reci9-open-source/#context","text":"Open source software refers to software where the code is openly available, allowing contributors to freely run, modify, contribute, and redistribute the code. These projects provide a great learning experience of working with large codebases to beginner programmers, and give you the opportunity to contribute to software that\u2019s used by a large number of community members. The general criteria for an open source project: - Repository must be public & open to outside contributors - Repository must have an open source license","title":"Context"},{"location":"recitations/reci9-open-source/#scavenger-hunt-30-min","text":"Join the slide deck made by your TA for your class and make a copy of the slide for your team. Then, search for open source projects to fill each square in the Scavenger Hunt table. Each project can only count for one square. The goal is to have as many squares filled as possible! Squares marked with ** can only be claimed by one team in the room - you must fulfill what\u2019s described in the square to claim it.","title":"Scavenger Hunt (30 min)"},{"location":"recitations/reci9-open-source/#reflection-10-min","text":"With your team, discuss the following questions: - Which attributes make a good open source project? A bad open source project? - Which projects did you find that you would most like to work on? Which would you least like to work on? Why?","title":"Reflection (10 min)"},{"location":"recitations/reci9-open-source/#resources","text":"A list of beginner friendly projects: https://github.com/MunGell/awesome-for-beginners Github Showcase for new contributors: https://github.com/showcases/great-for-new-contributors Issues that are labeled \u201cup-for-grabs\u201d: https://up-for-grabs.net Apache projects: http://www.apache.org/ Mozilla projects: https://developer.mozilla.org/en-US/docs/MDN/Community/Contributing Mozilla has a number of Open Source projects (including Firefox and Thunderbird) that are actively being developed and they recommend bugs for new contributors","title":"Resources"}]}